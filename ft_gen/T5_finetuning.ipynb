{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZviqXuVkaJb",
        "outputId": "a633808c-b87f-4ab2-fc1c-607287d1c258"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsDRy9SK47Vc"
      },
      "source": [
        "\n",
        "\n",
        "*   Import all necessary libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fXkwsuyPP54",
        "outputId": "4be28d64-002b-47cc-b2c1-8ed8716ca870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed transformers-4.36.2\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.16.0-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pyarrow-hotfix, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.16.0 dill-0.3.7 multiprocess-0.70.15 pyarrow-hotfix-0.6\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.5.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.23.5)\n",
            "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.25.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U transformers\n",
        "!pip install -U datasets\n",
        "!pip install tensorboard\n",
        "!pip install sentencepiece\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCl22QM5-4J1",
        "outputId": "8c7199ad-8518-42c7-ab7c-4ecf78db10e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "\n",
        "from transformers import AutoModelForCausalLM, GenerationConfig, AutoTokenizer\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "SEED_VAL = 42\n",
        "\n",
        "random.seed(SEED_VAL)\n",
        "np.random.seed(SEED_VAL)\n",
        "torch.manual_seed(SEED_VAL)\n",
        "torch.cuda.manual_seed_all(SEED_VAL)\n",
        "# used only for splitting the training set into train and val\n",
        "# we don't want to randomly split the whole dataset\n",
        "# we want to use the corpus's splits, so that we can compare results with others\n",
        "\n",
        "from transformers import GPT2LMHeadModel, GPT2Config, GPT2LMHeadModel\n",
        "from transformers import (\n",
        "    T5Tokenizer,\n",
        "    T5ForConditionalGeneration)\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from transformers.optimization import Adafactor, AdafactorSchedule\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt') # library that divides a text into a list of sentences\n",
        "\n",
        "MAX_LENGTH = 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHfDS_Q9k7RA"
      },
      "source": [
        "# Prepare data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if1C74mbA_NY"
      },
      "source": [
        "\n",
        "*   Download 20 news groups using the sklearn library in Python\n",
        "*   Acess the text data and store them in data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2YtobJp8OSKy",
        "outputId": "305367d6-81b7-48b1-9d01-d13e06653e84"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b8c23ad3-5784-4830-807b-28ba7fc39574\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>news</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8c23ad3-5784-4830-807b-28ba7fc39574')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b8c23ad3-5784-4830-807b-28ba7fc39574 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b8c23ad3-5784-4830-807b-28ba7fc39574');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c3270777-2ac2-4b87-ab98-99b5233ea629\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c3270777-2ac2-4b87-ab98-99b5233ea629')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c3270777-2ac2-4b87-ab98-99b5233ea629 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                news\n",
              "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...\n",
              "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...\n",
              "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...\n",
              "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...\n",
              "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import pandas as pd\n",
        "\n",
        "# Download the dataset's splits\n",
        "newsgroups_data_train = fetch_20newsgroups(subset='train')\n",
        "\n",
        "df = pd.DataFrame(newsgroups_data_train.data, columns=['news'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6kk0tJCIyp1"
      },
      "source": [
        "\n",
        "\n",
        "* Preprocessing the dataset \"data\" to extract the subject  and the message body from each message.\n",
        "* Formating it to a specific structure with the subject followed by a summary indicator ('; TLDR: ') and the message body.\n",
        "* In the test split, we don't add the message body, as that's what we want the model to learn to generate.\n",
        "* However, we save it separately so that we can use evaluation metrics with the reference later.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UtUmx1KoUaeR",
        "outputId": "078d5f1b-5221-4b5b-b716-1de776ee7aaf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e3396c26-b8e9-4a9a-8a95-f8804c6b7963\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject_and_body_prompt</th>\n",
              "      <th>subject_prompt</th>\n",
              "      <th>body_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>summarize: WHAT car is this!?; I was wondering...</td>\n",
              "      <td>summarize: WHAT car is this!?</td>\n",
              "      <td>I was wondering if anyone out there could enl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>summarize: SI Clock Poll - Final Call;A fair n...</td>\n",
              "      <td>summarize: SI Clock Poll - Final Call</td>\n",
              "      <td>A fair number of brave souls who upgraded thei...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>summarize: PB questions...;well folks, my mac ...</td>\n",
              "      <td>summarize: PB questions...</td>\n",
              "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>summarize: Re: Weitek P9000 ?;Robert J.C. Kyan...</td>\n",
              "      <td>summarize: Re: Weitek P9000 ?</td>\n",
              "      <td>Robert J.C. Kyanko (rob@rjck.UUCP) wrote: &gt; ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>summarize: Re: Shuttle Launch Question;From ar...</td>\n",
              "      <td>summarize: Re: Shuttle Launch Question</td>\n",
              "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3396c26-b8e9-4a9a-8a95-f8804c6b7963')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e3396c26-b8e9-4a9a-8a95-f8804c6b7963 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e3396c26-b8e9-4a9a-8a95-f8804c6b7963');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-97458e1a-af8f-4b57-96cb-4468856eeac7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-97458e1a-af8f-4b57-96cb-4468856eeac7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-97458e1a-af8f-4b57-96cb-4468856eeac7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                             subject_and_body_prompt  \\\n",
              "0  summarize: WHAT car is this!?; I was wondering...   \n",
              "1  summarize: SI Clock Poll - Final Call;A fair n...   \n",
              "2  summarize: PB questions...;well folks, my mac ...   \n",
              "3  summarize: Re: Weitek P9000 ?;Robert J.C. Kyan...   \n",
              "4  summarize: Re: Shuttle Launch Question;From ar...   \n",
              "\n",
              "                           subject_prompt  \\\n",
              "0           summarize: WHAT car is this!?   \n",
              "1   summarize: SI Clock Poll - Final Call   \n",
              "2              summarize: PB questions...   \n",
              "3           summarize: Re: Weitek P9000 ?   \n",
              "4  summarize: Re: Shuttle Launch Question   \n",
              "\n",
              "                                         body_output  \n",
              "0   I was wondering if anyone out there could enl...  \n",
              "1  A fair number of brave souls who upgraded thei...  \n",
              "2  well folks, my mac plus finally gave up the gh...  \n",
              "3  Robert J.C. Kyanko (rob@rjck.UUCP) wrote: > ab...  \n",
              "4  From article <C5owCB.n3p@world.std.com>, by to...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "# tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "\n",
        "subject_and_body_prompt, subject_prompt, body_output = [], [], []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  el = row['news']\n",
        "  lines = el.split('\\n')\n",
        "\n",
        "  body, subject, element = '', '', ''\n",
        "\n",
        "  for line in lines:\n",
        "    # save the subject\n",
        "    if 'Subject:' in line:\n",
        "      subject = line[len('Subject:') + 1:]\n",
        "\n",
        "    # ignoring other headers\n",
        "    elif len(re.findall(\"^[A-Za-z-_\\.]+:\", line)) != 0:\n",
        "      continue\n",
        "\n",
        "    # save the body, respecting the model's maximum nr of tokens\n",
        "    elif len(line) > 1:\n",
        "      if (len(body.split(' '))):\n",
        "        body += line + ' '\n",
        "\n",
        "  # input: subject ; TLDR: body\n",
        "  # we put backwards so that the model learns to generate the continuation\n",
        "  full_element = 'summarize: ' + subject + ';' + body[:-1]\n",
        "  subject_element = 'summarize: ' + subject\n",
        "\n",
        "  subject_and_body_prompt.append(full_element)\n",
        "  subject_prompt.append(subject_element)\n",
        "  body_output.append(body[:-1])\n",
        "\n",
        "df['subject_and_body_prompt'] = subject_and_body_prompt\n",
        "df['subject_prompt'] = subject_prompt\n",
        "df['body_output'] = body_output\n",
        "\n",
        "df = df.drop(columns=['news'])\n",
        "df.head()\n",
        "#len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-pU_dqohxkK"
      },
      "outputs": [],
      "source": [
        "val   = df.sample(n=100, random_state=SEED_VAL)\n",
        "train = df.loc[~df.index.isin(val.index)]\n",
        "\n",
        "#Reset the indexes\n",
        "val   = val.reset_index()\n",
        "train = train.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keDMXFSTibKR"
      },
      "outputs": [],
      "source": [
        "val.head()\n",
        "#len(val)\n",
        "\n",
        "# save val output as a reference for evaluation in the future\n",
        "with open('drive/MyDrive/reference_output.txt', 'w') as outfile:\n",
        "  for index, row in val.iterrows():\n",
        "    outfile.write(row['body_output'] + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9Gq-hPa9ic3x",
        "outputId": "e45f8f9b-0b39-42f6-a620-47a3a9ec080e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-564fb2e4-19b2-4460-b54c-2be6faa015ad\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>subject_and_body_prompt</th>\n",
              "      <th>subject_prompt</th>\n",
              "      <th>body_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>summarize: WHAT car is this!?; I was wondering...</td>\n",
              "      <td>summarize: WHAT car is this!?</td>\n",
              "      <td>I was wondering if anyone out there could enl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>summarize: SI Clock Poll - Final Call;A fair n...</td>\n",
              "      <td>summarize: SI Clock Poll - Final Call</td>\n",
              "      <td>A fair number of brave souls who upgraded thei...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>summarize: PB questions...;well folks, my mac ...</td>\n",
              "      <td>summarize: PB questions...</td>\n",
              "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>summarize: Re: Weitek P9000 ?;Robert J.C. Kyan...</td>\n",
              "      <td>summarize: Re: Weitek P9000 ?</td>\n",
              "      <td>Robert J.C. Kyanko (rob@rjck.UUCP) wrote: &gt; ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>summarize: Re: Shuttle Launch Question;From ar...</td>\n",
              "      <td>summarize: Re: Shuttle Launch Question</td>\n",
              "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-564fb2e4-19b2-4460-b54c-2be6faa015ad')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-564fb2e4-19b2-4460-b54c-2be6faa015ad button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-564fb2e4-19b2-4460-b54c-2be6faa015ad');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-63f5c31f-252b-4bbc-9d97-f38a263ade45\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-63f5c31f-252b-4bbc-9d97-f38a263ade45')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-63f5c31f-252b-4bbc-9d97-f38a263ade45 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   index                            subject_and_body_prompt  \\\n",
              "0      0  summarize: WHAT car is this!?; I was wondering...   \n",
              "1      1  summarize: SI Clock Poll - Final Call;A fair n...   \n",
              "2      2  summarize: PB questions...;well folks, my mac ...   \n",
              "3      3  summarize: Re: Weitek P9000 ?;Robert J.C. Kyan...   \n",
              "4      4  summarize: Re: Shuttle Launch Question;From ar...   \n",
              "\n",
              "                           subject_prompt  \\\n",
              "0           summarize: WHAT car is this!?   \n",
              "1   summarize: SI Clock Poll - Final Call   \n",
              "2              summarize: PB questions...   \n",
              "3           summarize: Re: Weitek P9000 ?   \n",
              "4  summarize: Re: Shuttle Launch Question   \n",
              "\n",
              "                                         body_output  \n",
              "0   I was wondering if anyone out there could enl...  \n",
              "1  A fair number of brave souls who upgraded thei...  \n",
              "2  well folks, my mac plus finally gave up the gh...  \n",
              "3  Robert J.C. Kyanko (rob@rjck.UUCP) wrote: > ab...  \n",
              "4  From article <C5owCB.n3p@world.std.com>, by to...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()\n",
        "#len(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSKYSS9VCib-"
      },
      "source": [
        "\n",
        "\n",
        "*   Setting GPT2 Tokenizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrh3YLrnC0ki"
      },
      "source": [
        "\n",
        "\n",
        "*   Defining a custom dataset 'GPT2Dataset' for pytorch which will be used for model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6_c0CJsAPPI"
      },
      "outputs": [],
      "source": [
        "# https://github.com/francoisstamant/lyrics-generation-with-GPT2/blob/main/GPT2_final.ipynb\n",
        "class NewsDataset(Dataset):\n",
        "  def __init__(self, dataframe, max_length=MAX_LENGTH, split='train'):\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
        "    # self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "    self.news_count = 0\n",
        "    self.subjects = []\n",
        "    self.bodies = []\n",
        "\n",
        "    for index, row in dataframe.iterrows():\n",
        "      subject = row['subject_prompt']\n",
        "      body = row['body_output']\n",
        "\n",
        "      subject_encoding = self.tokenizer(\n",
        "          subject,\n",
        "          return_tensors='pt',\n",
        "          max_length=max_length,\n",
        "          padding='max_length'\n",
        "      )['input_ids'][0][:1024]\n",
        "\n",
        "      body_encoding = self.tokenizer(\n",
        "          body,\n",
        "          return_tensors='pt',\n",
        "          max_length=max_length,\n",
        "          padding='max_length'\n",
        "      )['input_ids'][0][:1024]\n",
        "\n",
        "      self.subjects.append(subject_encoding.clone().detach())\n",
        "      self.bodies.append(body_encoding.clone().detach())\n",
        "\n",
        "    self.news_count = len(self.subjects)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.news_count\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.subjects[idx], self.bodies[idx]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxxDG48kGLNt"
      },
      "source": [
        "\n",
        "\n",
        "Creating the custom dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "55e3c756adde40c18fbcf3acde5423f8",
            "b524834f8b414485850c1dee1dd014cd",
            "d15b51d3188a454897ef4856a7cdecbd",
            "d2850950d5754cd784e53cf9c80249e8",
            "7168e79d74c245389d93daa05d7878fe",
            "b66dc19fd9b5466fa24c8f874ec2864c",
            "84ad48ee7c35447fb0ac8b5c7227cfa6",
            "a8a52ed379d14e149db9405669c66a1a",
            "3952f767ae9343009ed820a2baf7a207",
            "a49df3da0b14435f8d9c5785544af28b",
            "3fa26c51bc4d4e2e8abc0aa0d700e6f4",
            "1d75cb6e254a4831a32e8cec85599cfb",
            "8d2f0364d6784ca3a9c9271481966e78",
            "6338806ce15448a28135496edd3f7c18",
            "f855834c6fd346779bb56714d9b71a37",
            "e4b3446c11a24d73bf1f8d54bfa26f96",
            "fd8323f478c04388879078e0969bc079",
            "1ed67a1e9fcd4f8fa0c604de6adb73d5",
            "a434e7ca027b49cab49c8b970db7909c",
            "321b1a69883542a6a0e0217787b31490",
            "7f03a447c14c4903a66b135352b37060",
            "5c5fa62661ff40c095c285bd56d2f2eb",
            "c67b4dfcca7b4e048333077f3d61d577",
            "24573e0a215f40d39656221f00068cbf",
            "6309e5e0c1134b99bf86af05ab5e0fcd",
            "8b144412725a49f5aba0976617f26cdc",
            "b942864395754c9684ff7ef7f3aa0e73",
            "ccce8832960849e6979223532e40f60d",
            "efa08318e8fc42b2b367c09475413a23",
            "d5f01a6dbf584731b2fd87d39e65b8e7",
            "e1d77f25410c43fdb93c8b513d8078b0",
            "776ec07692e146638b9b40aad6cc8814",
            "d8b184cd953f418897ec8ceba1456e04"
          ]
        },
        "id": "CDhxFgeFA5nO",
        "outputId": "db72ba83-0152-4fe2-a183-40064dc00562"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55e3c756adde40c18fbcf3acde5423f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d75cb6e254a4831a32e8cec85599cfb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c67b4dfcca7b4e048333077f3d61d577",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_dataset = NewsDataset(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-6l_uuMqABa",
        "outputId": "69f40927-1b02-4a78-8087-610a657a7cbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11214"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1OKUMza_THP"
      },
      "outputs": [],
      "source": [
        "val_dataset = NewsDataset(val, split='val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR4-IGDt_VYM",
        "outputId": "cb029e95-c4b4-453d-b8fe-9af32a342fc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(val_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8zLeaGDlB1Q"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "3caa5b588aae4b0c801008c8fcc0a0d3",
            "bd9c0b17f06f44f6ab2a4c6c3a4263c7",
            "0c8f3ee5ad4e4685ac6db72ab72996cb",
            "71af837a097a41bbad0af33f23db8891",
            "1a5f209070e84ed0857d0e6f9ca416bb",
            "609e4cac76c949a9aee582c7b229a016",
            "1fe415dec4a943aa9256ec52fbec5b1a",
            "a28eaf02920746c48b129fa9365589d5",
            "ba5cc303d8d54defaca056607bbca637",
            "c0edb19549154bda9184dd0998bdcc57",
            "f5386ef74d5c4081b877236e302c12e9",
            "b3199bf3ce634e0eb79addef54c803d2",
            "de55b0ced39f42b4ba8107994b5d4c2c",
            "c8c7ee5d989b4e5d93f44cae536e77e4",
            "0311ba6ddd6747b493b665088e264e3e",
            "defffcd0ea3447d48ec47ad2c9302670",
            "74489e9e19934688b7b81d7a0c281135",
            "844c95e38018458780d323cacdcfc7e7",
            "54c3b399b9584a09a7a8c490547201cf",
            "3e199622a303426d8774e64ff4e9f65a",
            "cfb031f85b8741238ab093604ce67c1d",
            "a0ae12a671f348f18781c59c4e9a19a0",
            "54f4fa1afd0b4487b616108e1c73e372",
            "0be19a9004074149a2c452fb8eeddee5",
            "c977fe7d9fe547d792e1d9240831b906",
            "a547240588ea48f39719115d8ba91b3c",
            "952dca5debd04f6096ea1cf2aca88065",
            "339457b78c18460ab677088984211f78",
            "6e58beda6116409fbc49a8c9954a9904",
            "fffa10027ea04373b66ceac49223420e",
            "b27571c22c584b8aa14b29df5e3209e1",
            "bb528c2717f048b981db4cd79b401234",
            "e4131f9460e74e59a24e999ac5e51ca6"
          ]
        },
        "id": "Td0ULuwADiDY",
        "outputId": "ce068efd-cbdf-478f-b583-47a80d641e9f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3caa5b588aae4b0c801008c8fcc0a0d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3199bf3ce634e0eb79addef54c803d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54f4fa1afd0b4487b616108e1c73e372",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from transformers import AutoModelForPreTraining\n",
        "tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
        "model =T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "# model = AutoModelForPreTraining.from_pretrained('gpt2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTWcBGhQkG_T"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(\n",
        "    dataset, model, tokenizer,\n",
        "    batch_size=1, epochs=20, lr=2e-5,\n",
        "    max_seq_len=MAX_LENGTH, warmup_steps=200,\n",
        "    gpt2_type=\"gpt2\", output_dir=\"drive/MyDrive/\", output_prefix=\"gpt2_fine-tuning\",\n",
        "    test_mode=False,save_model_on_epoch=False,\n",
        "):\n",
        "\n",
        "    acc_steps = 100\n",
        "    device=torch.device(\"cuda\")\n",
        "    model = model.cuda()\n",
        "    model.train()\n",
        "\n",
        "\n",
        "    optimizer = Adafactor(model.parameters(), scale_parameter=False, relative_step=False, warmup_init=False, lr=lr)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=warmup_steps, num_training_steps=-1\n",
        "    )\n",
        "    train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    loss=0\n",
        "    accumulating_batch_count = 0\n",
        "    input_tensor = None\n",
        "\n",
        "    loss_values = []\n",
        "    ppl_values = []\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        running_ppl = 0.0\n",
        "\n",
        "        print(f\"Training epoch {epoch}\")\n",
        "        print('Loss: ', loss)\n",
        "        if epoch != 0:\n",
        "            print('Average loss: ', loss_values[-1])\n",
        "            print('Average perplexity: ', ppl_values[-1])\n",
        "\n",
        "        for idx, entry in tqdm(enumerate(train_dataloader)):\n",
        "            subject, body = entry[0], entry[1]\n",
        "\n",
        "            if (subject.size()[-1] != body.size()[-1]):\n",
        "                #print('different sizes')\n",
        "                continue\n",
        "            #print(subject.size())\n",
        "            #print(body.size())\n",
        "            input_tensor = subject.to(device)\n",
        "            continuation = body.to(device)\n",
        "            outputs = model(input_tensor, labels=continuation)\n",
        "            loss = outputs[0]\n",
        "            loss.backward()\n",
        "\n",
        "            running_loss =+ loss.item() * batch_size # batch size\n",
        "\n",
        "            if (accumulating_batch_count % batch_size) == 0:\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "                model.zero_grad()\n",
        "\n",
        "            accumulating_batch_count += 1\n",
        "            input_tensor = None\n",
        "\n",
        "            # # # # # # # # perplexity # # # # # # # #\n",
        "            encodings = body\n",
        "            max_length = model.config.n_positions\n",
        "            stride = 512\n",
        "            seq_len = len(encodings)\n",
        "\n",
        "            nlls = []\n",
        "            prev_end_loc = 0\n",
        "            for begin_loc in range(0, seq_len, stride):\n",
        "                end_loc = min(begin_loc + max_length, seq_len)\n",
        "                trg_len = end_loc - prev_end_loc  # may be different from stride on last loop\n",
        "                input_ids = encodings[begin_loc:end_loc].to(device)\n",
        "                target_ids = input_ids.clone()\n",
        "                target_ids[:-trg_len] = -100\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(input_ids, labels=target_ids)\n",
        "                    neg_log_likelihood = outputs.loss\n",
        "\n",
        "                nlls.append(neg_log_likelihood)\n",
        "                prev_end_loc = end_loc\n",
        "                if end_loc == seq_len:\n",
        "                    break\n",
        "            ppl = torch.exp(torch.stack(nlls).mean())\n",
        "            running_ppl =+ ppl * batch_size # batch size\n",
        "            # # # # # # # #\n",
        "\n",
        "        loss_values.append(running_loss / len(dataset))\n",
        "        ppl_values.append(running_ppl / len(dataset))\n",
        "\n",
        "    #plt.plot(loss_values)\n",
        "    #plt.plot(ppl_values)\n",
        "    return model, loss_values, ppl_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkFkgof79y1z"
      },
      "outputs": [],
      "source": [
        "#!pip install light-the-torch\n",
        "#!ltt install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eLKTyx56TjN",
        "outputId": "455a7023-eb19-459e-e827-32086c76a10d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training epoch 0\n",
            "Loss:  0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "11214it [1:07:35,  2.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training epoch 1\n",
            "Loss:  tensor(3.3771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Average loss:  0.000301147306669156\n",
            "Average perplexity:  tensor(0.0018, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "11214it [1:07:30,  2.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training epoch 2\n",
            "Loss:  tensor(2.3564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Average loss:  0.0002101278356079624\n",
            "Average perplexity:  tensor(0.0005, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "11214it [1:07:28,  2.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training epoch 3\n",
            "Loss:  tensor(1.6826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Average loss:  0.00015004178260298405\n",
            "Average perplexity:  tensor(0.0003, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4400it [26:23,  2.72it/s]"
          ]
        }
      ],
      "source": [
        "model, loss_values, ppl_values = train_model(train_dataset, model, tokenizer, epochs=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1FMJ815HA-p"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'drive/MyDrive/fine-tuned-t5.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRl5_jKsulpO"
      },
      "outputs": [],
      "source": [
        "loss_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywIA6CTfuok8"
      },
      "outputs": [],
      "source": [
        "ppl_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W1VY5mAAQm7"
      },
      "source": [
        "# Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "q8QazQoVAd4J",
        "outputId": "08aa6918-2273-4b71-e4a5-9b12cbe1ea86"
      },
      "outputs": [],
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "model.load_state_dict(torch.load('drive/MyDrive/fine-tuned-t5.pt'))\n",
        "model.eval()\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "# tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# add the EOS token as PAD token to avoid warnings\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POvbXwg08HUj"
      },
      "source": [
        "## Greedy search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNWFA7nR9tIq"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "greedy_outputs = []\n",
        "for index, row in val.iterrows():\n",
        "  # encode context the generation is conditioned on\n",
        "  model_inputs = tokenizer(row['subject_prompt'], return_tensors='pt')\n",
        "\n",
        "  greedy_output = model.generate(\n",
        "      **model_inputs,\n",
        "      max_new_tokens=MAX_LENGTH - len(model_inputs['input_ids'][0]))\n",
        "\n",
        "  text = tokenizer.decode(greedy_output[0], skip_special_tokens=True)\n",
        "  greedy_outputs.append(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "552G-A8v-4Qc"
      },
      "outputs": [],
      "source": [
        "for index, row in val.iterrows():\n",
        "  print(row['subject_prompt'])\n",
        "  print(greedy_outputs[index])\n",
        "  if index == 3:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dE2ULmiE_Xfq"
      },
      "outputs": [],
      "source": [
        "# save output to file\n",
        "with open('drive/MyDrive/t5-greedy_output-2.txt', 'w') as outfile:\n",
        "  for index, row in val.iterrows():\n",
        "    outfile.write(greedy_outputs[index].replace(\"\\n\", \" \") + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw_5taCj8KHJ"
      },
      "source": [
        "## Beam search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u97Zf0IK_sVd"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "beam_outputs = []\n",
        "\n",
        "for index, row in val.iterrows():\n",
        "  # encode context the generation is conditioned on\n",
        "  model_inputs = tokenizer(row['subject_prompt'], return_tensors='pt')\n",
        "\n",
        "  beam_output = beam_output = model.generate(\n",
        "    **model_inputs,\n",
        "    max_new_tokens=MAX_LENGTH - len(model_inputs['input_ids'][0]),\n",
        "    num_beams=5,\n",
        "    no_repeat_ngram_size=2,\n",
        "    early_stopping=True\n",
        "  )\n",
        "\n",
        "  text = tokenizer.decode(beam_output[0], skip_special_tokens=True)\n",
        "  beam_outputs.append(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7-Kizar_sdL"
      },
      "outputs": [],
      "source": [
        "# save output to file\n",
        "with open('drive/MyDrive/t5-beam_output.txt', 'w') as outfile:\n",
        "  for index, row in val.iterrows():\n",
        "    outfile.write(beam_outputs[index][len(row['subject_prompt']):].replace(\"\\n\", \" \") + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gegujAQH8NOX"
      },
      "source": [
        "## Top-k sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f822N0sZAZvf"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "topk_outputs = []\n",
        "for index, row in val.iterrows():\n",
        "  # encode context the generation is conditioned on\n",
        "  model_inputs = tokenizer(row['subject_prompt'], return_tensors='pt')\n",
        "\n",
        "  topk_output = sample_output = model.generate(\n",
        "      **model_inputs,\n",
        "      max_new_tokens=MAX_LENGTH - len(model_inputs['input_ids'][0]),\n",
        "      do_sample=True,\n",
        "      top_k=50\n",
        "  )\n",
        "\n",
        "  text = tokenizer.decode(topk_output[0], skip_special_tokens=True)\n",
        "  topk_outputs.append(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6iPGMpUAZ5z"
      },
      "outputs": [],
      "source": [
        "# save output to file\n",
        "with open('drive/MyDrive/t5-topk_output.txt', 'w') as outfile:\n",
        "  for index, row in val.iterrows():\n",
        "    outfile.write(topk_outputs[index][len(row['subject_prompt']):].replace(\"\\n\", \" \") + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4Ng9nOf8b28"
      },
      "source": [
        "## Top-p sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxJjJhGWBAaZ"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "topp_outputs = []\n",
        "for index, row in val.iterrows():\n",
        "  # encode context the generation is conditioned on\n",
        "  model_inputs = tokenizer(row['subject_prompt'], return_tensors='pt')\n",
        "\n",
        "  topp_output = model.generate(\n",
        "      **model_inputs,\n",
        "      max_new_tokens=MAX_LENGTH - len(model_inputs['input_ids'][0]),\n",
        "      do_sample=True,\n",
        "      top_p=0.92,\n",
        "      top_k=0\n",
        "  )\n",
        "\n",
        "\n",
        "  text = tokenizer.decode(topp_output[0], skip_special_tokens=True)\n",
        "  topp_outputs.append(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxdLZPLOBAko"
      },
      "outputs": [],
      "source": [
        "# save output to file\n",
        "with open('drive/MyDrive/t5-topp_output.txt', 'w') as outfile:\n",
        "  for index, row in val.iterrows():\n",
        "    outfile.write(topp_outputs[index][len(row['subject_prompt']):].replace(\"\\n\", \" \") + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd5_sX8qsGLr"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_Pm0eFLsRau"
      },
      "source": [
        "## SEScore\n",
        "\n",
        "[Source code](https://github.com/xu1998hz/SEScore)\n",
        "\n",
        "- Currently down... See implementation and if it's feasible to recreate it (e.g., if it doesn't require too many resources)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PqWSmmVs17l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vtngyAosUCP"
      },
      "source": [
        "## EmbSim\n",
        "\n",
        "[Source code](https://github.com/geek-ai/Texygen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKZi0VjLsWb6"
      },
      "source": [
        "## NLLTest\n",
        "\n",
        "[Source code](https://github.com/geek-ai/Texygen)\n",
        "\n",
        "From [PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss): `torch.nn.functional.nll_loss(input, target)`\n",
        "- `input` has dimensions (N,C) and contains log-probabilities of each word generated by the model. Each entry i is the log-prob of word i being from class j (equal to word j)\n",
        "\n",
        "- `target` has dimension (N) and contains the real index in the vocabulary of the real input data. Each entry i is the index of the word (between 0 and C-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE__LJqkTlj4"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoucVWVPnR84"
      },
      "source": [
        "# Calculate Scores of Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4S2Yq3hadGB"
      },
      "outputs": [],
      "source": [
        "metrics = {}\n",
        "# https://blog.paperspace.com/automated-metrics-for-evaluating-generated-text/ might be helpful"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsQ_oM0yCZDr",
        "outputId": "5a436c49-46a6-4cef-cac0-88fd50488fda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ],
      "source": [
        "%pip install nltk\n",
        "%pip install rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYuEtcY7yo0T"
      },
      "outputs": [],
      "source": [
        "hypothesis = \"It is a guide to action which ensures that the military always obeys the commands of the party. He read the book because he was interested in world history.\"\n",
        "references = \"It is a guide to action that ensures that the military will forever heed Party commands. It is the guiding principle which guarantees the military forces always being under the command of the Party. It is the practical guide for the army always to heed the directions of the  party. He was interested in world history because he read the book.\"\n",
        "\"\"\"\n",
        "hyp1 = ['It', 'is', 'a', 'guide', 'to', 'action', 'which',\n",
        "    ...         'ensures', 'that', 'the', 'military', 'always',\n",
        "    ...         'obeys', 'the', 'commands', 'of', 'the', 'party']\n",
        "    >>> ref1a = ['It', 'is', 'a', 'guide', 'to', 'action', 'that',\n",
        "    ...          'ensures', 'that', 'the', 'military', 'will', 'forever',\n",
        "    ...          'heed', 'Party', 'commands']\n",
        "    >>> ref1b = ['It', 'is', 'the', 'guiding', 'principle', 'which',\n",
        "    ...          'guarantees', 'the', 'military', 'forces', 'always',\n",
        "    ...          'being', 'under', 'the', 'command', 'of', 'the', 'Party']\n",
        "    >>> ref1c = ['It', 'is', 'the', 'practical', 'guide', 'for', 'the',\n",
        "    ...          'army', 'always', 'to', 'heed', 'the', 'directions',\n",
        "    ...          'of', 'the', 'party']\n",
        "\n",
        "    >>> hyp2 = ['he', 'read', 'the', 'book', 'because', 'he', 'was',\n",
        "    ...         'interested', 'in', 'world', 'history']\n",
        "    >>> ref2a = ['he', 'was', 'interested', 'in', 'world', 'history',\n",
        "    ...          'because', 'he', 'read', 'the', 'book']\n",
        "\"\"\"\n",
        "\n",
        "import re\n",
        "\n",
        "def clean_tokens(sentence_tokenized):\n",
        "  for i in range(len(sentence_tokenized)):\n",
        "    sentence_tokenized[i] = re.sub('[^A-Za-z ]', '', sentence_tokenized[i])\n",
        "  return sentence_tokenized\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a9RXrCQTr5P",
        "outputId": "9fcf3e98-f41d-4c4a-91b5-a1fc11ca56a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['\\n', '\\n', '\\n', '\\n', 'g.\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 's.\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', ' form of sexism.\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'in a row.\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', ' u.s.\\n', '\\n', '\\n', 'ble for mac mobile.\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'gland scout.\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n",
            "['Could someone please post any info on these systems. Thanks. BoB --  ----------------------------------------------------------------------  Robert Novitskey | \"Pursuing women is similar to banging one\\'s head rrn@po.cwru.edu  |  against a wall...with less opportunity for reward\"  ---------------------------------------------------------------------- \\n', \"In article <1993Apr6.040254.8443@cs.brown.edu> ksl@engin1.NoSubdomain.NoDomain (Kiseok Lee  ) writes: >From: ksl@engin1.NoSubdomain.NoDomain (Kiseok Lee  ) >Date: Tue, 6 Apr 1993 04:02:54 GMT >In article <C51H9M.46p@news.cso.uiuc.edu>, rhc52134@uxa.cso.uiuc.edu (Richard) writes: >|> Geoffrey S. Elbo writes: >|>  >|> >Yes, and it is the fastest defrag I've ever watched.  It did a 170MB  >|> >hard disk in 20 minutes. >|>  >|> \\tI found the MS defrag looks very much like Norton Speedisk. >|> Is it just a strip-down version of the later? >|>  >|> \\tI have both Norton Speedisk and Backup, so I was wondering  >|> if I need to install MS Backup? >|>  >|> Richard >|>  >Yes, defragger IS come from Norton. >If you have Norton Utility, don't bother.      Don't bother if you have CPBackup or Fastback.  They all offer options  not available in the stripped-down MS version (FROM CPS!).  Examples - no  proprietary format (to save space), probably no direct DMA access, and no  tape drive!      You NEED MS Defrag if you use doublespace to work on the compressed  volume.\\n\", '5.25\" Internal Low density disk drive. Monochrome monitor 8088 motherboard, built in parallel and serial ports, built in mono and color output, 7Mhz. Libertarian, atheist, semi-anarchal Techno-Rat. I define myself--tsa@cellar.org\\n', \"Hi, In Canada, any gun that enters a National Park must be sealed (I think it's a small metal tag that's placed over the trigger).  The net result of this is that you _can't_ use a gun to protect yourself from bears (or psychos) in the National Parks.  Instead, one has to be sensitive to the dangers and annoyances of hiking in bear country, and take the appropriate precautions. I think this policy makes the users of the National Parks feel a little closer to Nature, that they are a part of Nature and, as such, have to deal with nature on it's own terms. Guy\\n\", 'In article <120666@netnews.upenn.edu> kkeller@mail.sas.upenn.edu (Keith Keller) writes: >My vote goes to John Vanbiesbrouck.  His mask has a skyline of New York >City, and on the sides there are a bunch of bees (Beezer).  It looks >really sharp. Doesn\\'t it also have the Statue of Liberty on it or is that Richter\\'s Mask? The back actually has a Bee followed by a Z to represent the Beezer. It  also has something that looks like the three interconnecting circles from the Led Zepplin 4 album cover. Is that what it is supposed to be? and if it is does anybody know why he would put it there? Ali? >    Keith Keller\\t\\t\\t\\tLET\\'S GO RANGERS!!!!! >            \"When I want your opinion, I\\'ll give it to you.\"  John \"The official Language of Golf is Profanity\" In Hockey Hell...............jwodzia@eng.clemson.edu............John R. Wodziak The REAL Black and Gold     |In Memorium: #7 Alan Kulwicki 1954-1993   | Bean Will Triumph over those who |A Polish Yankee Mechanical Engineer,      | Town are Pretenders to the Crown.|1992 Winston Cup Champion & a great Person| ROCKS!\\n', \"I'm thinking about upgrading my 030 50MHz to the 040 33version.  Has anyone had any experience with the accelerator, and if so - what do you think? Any problems, what are the speedometer results?, is it much faster than the 50MHz?  Basically, I'd appreciate hearing all about this product.  Please respond via email, and I'll summarize if there's a big response.  thanks in advance, Andrew\\n\", 'In article <C5IAK2.5zH@murdoch.acc.Virginia.EDU> gsh7w@fermi.clas.Virginia.EDU (Greg Hennessy) writes: > Clayton Cramer: >> But what came out, in much lower profile reporting, was that the >> \"victim\" was a prostitute, and the man had not paid her -- hence the >> false accusation. > There was no evidence the woman in question was a prostitute, the > defense merely alledged that she was. The fact that she was wearing a miniskirt with no underwear was presented as evidence that she was a prostitute, and the court apparently found this compelling. > Even Clayton knows the difference.  Err, perhaps Clayton doesn\\'t know > the difference. Clayton does indeed know the difference.  Greg apparently doesn\\'t. >> the judge found that there was some credible evidence that the Marines >> were engaged in self-defense. > No, the judge found that the prosecution did not carry out the burder > on proof. Because the judge found that there was some credible evidence that the Marines were engaged in self-defense.  Got it, knucklehead? > A small clipping from clarinews, under fair use guidelines:  >    New Hanover District Court Judge Jacqueline Morris-Goodson ruled in >    the benchtrial that the state failed to carry its burden in proving >    the Marines acted to cause injury. Because, in part [REPEAT AFTER ME], \"the judge found that there was some credible evidence that the Marines were engaged in self-defense\". Hopefully, one of these days you will understand. > Interesting that in 2 of the 3 cases Clayton does what he accuses > others of doing. With respect to credibility, I would rate Clayton Cramer an order of magnitude higher than a) the news media, and b) homosexuals. > But I never thought Clayton was consistent. Clayton is indeed consistent.  And so are you. --    The views expressed herein are   |  Theodore A. Kaldis   my own only.  Do you seriously   |  kaldis@remus.rutgers.edu   believe that a major university  |  {...}!rutgers!remus.rutgers.edu!kaldis   as this would hold such views??? |\\n', \"Does anybody have an X server for NT that they're willing to share files or experiences? Bill Steer Westinghouse\\n\", 'In article <28641@galaxy.ucr.edu> datadec@ucrengr.ucr.edu (kevin marcus) writes: >Are there any public domain or shareware astronomy programs which will >map out the sky at any given time, and allow you to locate planets, nebulae, >and so forth?  If so, is there any ftp site where I can get one? I posted my public-domain MSDOS program \"sunlight.zip\" to \"sci.astro\" yesterday. It easily locates the sun, moon, and planets, and can also be used to locate other objects if you input their Right Ascesion and Declination. Use \"uudecode\" to extract. --             Robert Sheaffer - Scepticus Maximus - sheaffer@netcom.com     Past Chairman, The Bay Area Skeptics - for whom I speak only when authorized!          \"Marxism and feminism are one and that one is Marxism\"                              - Heidi Hartmann and Amy Bridges,                        quoted by Catharine MacKinnon above the first chapter                        of her \"Toward a Feminist Theory of the State\"\\n', \"In article <Apr.15.21.39.43.1993.8726@romulus.rutgers.edu> kaldis@romulus.rutgers.edu (Theodore A. Kaldis) writes: >Perhaps 1%, but most likely not more than 2%.  A new study >(discrediting Kinsey) says so. >--  Yes, I saw today in 6 o'clock news on KCBS here in San Francisco this statistic quoted.  2.2% men had sex with another man. 1.3% cinsider themself homosexual. I understand of course that because this statistic goes against common believe and not PC-correct it must be complete BS. Thx vlad --  Vladimir Kuznetsov                         (408)252-5455 Natural Intelligence Consulting            vlad@netcom.COM                                            73437,3344@compuserve.com                                            vkuznetsov@mci.com\\n\", \"wolfson@regatta.sps.mot.com (Stephen Wolfson) writes: >In article <1993Mar31.193406.29625@ugle.unit.no> oep@colargol.edb.tih.no   >(oep) writes: >> which turns into a teenagers car when it gets old. The average   >lifelength of >> a Volvo in Norway is 18 years, and in Sweden 20 years) >Of course someone pointed out when Saab or Volvo was running their >At least 10 years ads, that the average milage was significantly >less than than the US average. That my be, but every Volvo I've ever owned has lasted far longer than most other cars..... 1981 Volvo 245....125,000 Miles, still on the road. 1983 Volvo 242....195,000 Miles, still on the road. 1984 Volvo 244....175,000 Miles, still on the road. And I'll admit, the dealer repair cost is high. But with some mechanical aptitude of your own, and finding a good indi mechanic, you can avoid most breakdowns, and make the rest cheap(The sum total of the repairs on the car with 195,000 miles has been 2 mufflers and a radiator. Whoa. Bad repair record).  And all of these cars are driven fairly hard. None of them are at the head of a line of cars going 30 MPH....the first two spend a lot of their operating life with the speedometer pegged...and the only reason the 84 doesn't is it has a 120 MPH speedo... What I want to know is....have all you people who hate Volvos been traumatized by someone in a 745 Turbo wagon blowing you away on the road, or what?\\n\", \"I have an Intel SatisFAXtion Modem/100 INTERNAL for sale. It runs at 2400 baud data mode and up to 9600 baud as a Class 1 fax modem. It transmits up to 9600 baud (V.29) and receives up to 4800 baud (V.27 ter.) The modem has all original manuals and comes with software, icluding   Intel's SatisFAXtion and FAXability, as well as Crosstalk Communicator I have used this modem less than an hour.  It came with my computer and I   already had another one. I would like to ask $50 for this modem, but will entertain all serious offers. Please email to jmu@acpub.duke.edu Thanks.\\n\", 'In article <May.2.09.51.49.1993.11841@geneva.rutgers.edu>, you wrote: > The genius of science is that it discovered that enormous progress  > in knowledge could be made by isolating the study of physical  > interactions for the more general areas of study and proceeding > not by logical argument but by experiment. The scientific method > is hypothesize, attempt to disprove the hypothesis, if you fail,  > publish, if others fail to disprove your hypothesis, accept it > as a working theory and move on. This method is suitable only > for the study of objects without will, objects which do not > take an interest in the experiment. Science does not progress via experimentation but by philosophising.  One aim of experiments is to investigate the validity of the hyptheses resulting from the models produced by this thinking process. > The arrogance of science is the assumption many advocates of  > science make that the scientific method is the only method of > serious study, the only one leading to knowledge rather than > belief.  Science has one advantage of all other approaches to explaining the world. It is objective. > Its further arrogance, is the assumption which arises > that, since science is the only valid method of thought, everything > which exists must be the sort of thing which the scientific  > method can study, and that if the scientific method cannot  > study it it either does not exist or cannot in any way be known. Anything which affects the physical world can be studied.  For example, since we are part of the physical world, anything (including spirits) which affects our behaviour can be observed.  Science does not make any claims about the existence or non-existence of objects which do not affect the physical world. > Since these asumptions about the nature of the world cannot > themselves be made the subject of experiment, it is bad science > to believe them, as well as arrogance, illogic, and just plain > sloppy thinking. The purpose of science is to produce a model of the *physical* world.  The model must be able to explain all past observations and predict the outcome of future observations.  One of the aims of experiments is to carry out well defined observations which are objective. Ideally scientist will except the model which best describes the world, and the model which realises on the minimal number of assumptions.  At the moment models which do not rely on the assumption of some *spiritual* world existing are equally powerful to ones which assume the assumption of a *spiritual* world.  As the non-spiritual models has fewer assumptions it should be the currently accepted models. The scientific process never assumes that its present models are the correct ones, whereas many religions claim to represent the truth.  The arrogance of many theists is that they claim to represent the truth, this cannot be said of scientists. Steve Lang SLANG->SLING->SLINK->SLICK->SLACK->SHACK->SHANK->THANK->THINK->THICK\\n', \"Hello world, I'm attempting to write an 8051 simulator on an IBM PC for teaching purposes, so that first-year elec-eng students can 'see' the workings of the microcontroller as it performs operations - logical ands, for example, being shown on a bit-by-bit basis (1 AND 1 = 1) so that the students can see that it's not really a mystical process, but totally logical, for example. Every instruction should show some 'working', and not just alter register/memory/port contents. Does anyone know of any freely-available example simulation code, in Pascal or Modula-2, that would show me where I'm going wrong in writing my simulator? [I'm using Ayala's -The 8051 Microcontroller- as a reference - the simulator supplied with the package is overkill for simple teaching purposes, I feel, and there's no source code to help you roll your own.] Please email me if you can help, or if you know of somewhere more  appropriate I should be posting this  - I rarely scan these groups. Thanks, Lloyd Wood L.H.Wood@lut.ac.uk \\n\", 'In article <1qhc2p$8d8@transfer.stratus.com>, cme@ellisun.sw.stratus.com (Carl Ellison) writes: > In article <1993Apr14.120229.15878@mnemosyne.cs.du.edu> rwebb@nyx.cs.du.edu (Russell Webb) writes: ... > Call me paranoid, but this is the same kind of scare story which Dorothy > Denning was citing while calling for the limitation of cryptography. >  > I doubt that DD is behind this --  >  > but I suspect that the FBI (and maybe NSA) are behind DD and those agencies > could easily be mounting a nationwide campaign (with our tax dollars?) to > build up public outcry against digital communication -- especially against > unbreakable, encrypted communication. >  >  > What\\'s going on here?? >  Haven\\'t you read any of Noam Chomsky\\'s works? A widely used information net outside the control of the \\'right people\\' is unthinkable. Hundreds of billions of dollars will be spent to wipe it out, sorry, \\'regulate and order it\\' once the major media and poitical powers wake up to the efect it can have. If you can\\'t be bothered reading, get the video \"Manufacturing Consent\". ~Paul\\n', \"In article <vzhivov.734637613@cunews> vzhivov@alfred.carleton.ca (Vladimir Zhivov) writes: Wales Conference, Adams Division, Semifinal >Boston vs. Buffalo: >The Bruins are playing some excellent hockey, and with Cam Neely back >and Moog his old self again this should be a cake-walk.  BRUINS IN 5. I'm hoping for a Fuhr miracle, but I agree that Boston will likely win the series.  Goaltending is about equal, top offensive players are about equal (Mogilny-LaFontaine vs. Oates-Juneau), but Buffalo has no answer to Neely (not to imply that Neely is not a top offensive player btw, in fact he's one of my favourites even though he's a damn Bruin :) ).  And the rest of the matchup wrt lineup favours Boston anyway.  But I think it will go six. >Quebec vs. Montreal: >This one is very tough to call. Montreal certainly has the experience >factor, but Quebec is more talented IMHO. It'll come down to the >goalies.  I'll go with experience and Roy. CANADIENS IN 7. Agreed here...but Montreal will be pushed to the limit.  Is it just me, or does everything Montreal does in the playoffs come down to Roy?  Go Habs!! Final >Boston vs. Montreal: >Will Bruin domination continue in this rivalry? Yes. Moog has >consistently outperformed Roy in the playoffs (after 1986)..[other stuff] > Bruins in five. I can't predict a Montreal victory because I've been watching them play for 6 weeks and IMO they severly need some tougher players, especially to play in the Garden.  Last time they beat the B's 5-2 but Boston had a clear territorial advantage; the victory was Roy's.  At the same time, I can't bring myself to predict the possibility of a loss, so I'll just say I will not be putting money on this series. :-) >Patrick Division, semifinal >Pittsburgh vs. NY Islanders: >What can I say? The Pens are flying high and have the most talent in >the league.  Agreed.  NY doesn't have the goaltending to stop the onslaught, independent of the trouble they have given Pittsburgh this year.  Pens in five, which is credit to NY. >Washington vs. New Jersey: >CAPITALS IN 5. Agreed here too, but I think it will go at least six.  Jersey has a decent team, and Washington has done poorly against the division this year. >Pittsburgh vs. Washington: >If the Caps had Bill Ranford I might see an upset, but Don Beaupre >just doesn't inspire my hopes.  PENGUINS IN 6. I think they will use Tabaracci more after Beaupre gets shelled.  I don't think it will go six either...*maybe* five. >CONFERENCE FINAL: >Pittsburgh vs. Boston: >A replay of last year. The Penguins are just as good as 12 months ago, >and the Bruins are much improved. But... PENGUINS IN 6. If Pittsburgh plays Boston, IMO they win in likely five, possibly six.  They own the Bruins.  If they play Montreal, I think it will go to seven, and once again I won't be putting money on the seventh game.  I say seven because the Habs have played Pittsburgh very tough this season. >Campbell Conference, Norris Division, semifinal >Chicago vs. St. Louis (or Minnesota): > BLACKHAWKS IN 5. Chicago will win, but I think in at least six.  Chicago is not that good, IMO.  And remember that they take ridiculous numbers of penalties. >Detroit vs. Toronto: >The Leafs have had an excellent season, but they've been playing >playoff hockey all year - the Habs under Burns were the same way and >always wilted in the playoffs.  RED WINGS IN 5. Very true.  The Leafs have much to be proud of, but they will soon find out why Montreal did so lousy in the playoffs.  Toronto might win two or three  at MLG though.  Wings in six, maybe even seven. >FINAL: >Chicago vs. Detroit: > This will be a war. Fedorov will win it in OT. RED WINGS IN 7. It _will_ be a war...possibly the most intense playoff series of them all.  And yes, I think Detroit will win.  Probert will have to come up big though. >Smythe Division SEMI-FINALS: >Vancouver vs. Winnipeg: > CANUCKS IN 7. Our first disagreement.  Canucks are playing like shit.  They don't use their size *at* *all*, which may explain why they get hammered 8-1 by a team chasing them (Calgary)....Winnipeg in six. >Calgary vs. Los Angeles: >This would have been tough to call, except for three things. 1/ The >Kings don't have a goalie; 2/ Gary Roberts will be back; 3/ the Kings >shot themselves in the foot by trading a proven winner (Paul Coffey) >for a proven loser (Jimmy Carson). Gretzky is just too weary to carry >this group. FLAMES IN 5. This is also tough for me to call, because I haven't seen the Smythe enough.  I don't think Roberts will be well enough to figure in, Coffey is a non-issue, who cares what Carson has done before, and *never* underestimate Gretzky.  LA in six. >FINAL: >Vancouver vs. Calgary: > FLAMES IN 6. If it is these two, Calgary will not need six games.  But I think it will be LA-Winnipeg anyway, and LA in seven, because of home ice. >COFERENCE FINAL: >Detroit vs. Calgary: > RED WINGS IN 7. Wow, must've been tough to go against your team.  But let's see, I picked LA-Detroit.  Detroit will win, probably in six. >STANLEY CUP FINAL: >Pittsburgh vs. Detroit: >Three in a row and official 'dynasty' status for the Pens? Or can the >Wings complete a dream season? Well, the Wings are better in goal (not >sufficiently so though IMHO) and have better D-men. However, Mario and >the boys can sure score. Look for Jagr to shine in the playoffs, >though I sure would love to see Probert beat some sense into him. The >Pens are just too much, especially since Detroit will have a tougher >battle to get here. PENGUINS IN 5. If Pittsburgh plays Detroit, it will go longer than five, and I wouldn't bet against the Wings.  They are very strong, IMO, and nobody knows *how* strong because they've been underachieving most of the year.  If forced to choose, though, I'd have to take the Penguins. A side note.  Vlad, last week you said that Selanne was a better player than Gilmour.  NO WAY.  He is a more talented pure goal scorer...but aside from the age difference, there is no way I would take him over Gilmour on my team. I'm not asking for flames, either, btw....I've spent more than enough time arguing on behalf of Selanne and I still say he's a great player.  But while he and Gilmour are both dangerous offensively (give Teemu an edge), Gilmour *does* *it* *all*.  I know a lot of Gilmour-bashing goes on, esp. from Flame fans.  But IMO you guys are letting your dislike of Gilmour cloud your judgement when it comes to his skill.  He is easily one of the best all-round players in the NHL. dchhabra@stpl.ists.ca\\n\", 'We are Dartmouth engineering students.We are looking for documented data regarding the wear associated with turning on an off a monitor and how it relates to power consumption.  Interested in a comparison between the wear on a monitor which is left on continuously and one which is turned off when not in use.   Please personalize E-mail to: ds@Dartmouth.edu Thank you, Dan Stern Oliver Weir\\n', \"In article <1993Apr6.195022.6362@alchemy.chem.utoronto.ca> golchowy@alchemy.chem.utoronto.ca (Gerald Olchowy) writes: >Major league baseball has told the Blue Jays and the Expos not to >sign Oscar Linares (I think that is his name) Linares has not defected; as I pointed out, MLB requires that the player defect first. >...Canada does not have the restrictions against >Cubans that the US has and other major league teams have told the >Canadian teams that they would be very unhappy if the Expos or the >Blue Jays would do this. What a surprise.  As long as the pool of talent is not accessible to all teams, MLB won't let a few teams sign it.  Seems perfectly reasonable to me.   >  Cubans players would not have to defect >to play in Canada and could play the 81 home games for the Expos >and Blue Jays without any trouble. Except that MLB won't allow it, which is all I ever said. Sherri Nichols snichols@adobe.com\\n\", 'In article <1993Apr19.162502.29802@news.eng.convex.com> cash@convex.com (Peter Cash) writes: >What causes those little brown spots on older people\\'s hands? Are they >called \"liver spots\" because they\\'re sort of liver-colored, or do they >indicate some actual liver dysfunction? Senile keratoses.  Have nothing to do with the liver. --  ---------------------------------------------------------------------------- Gordon Banks  N3JXP      | \"Skepticism is the chastity of the intellect, and geb@cadre.dsl.pitt.edu   |  it is shameful to surrender it too soon.\"  ----------------------------------------------------------------------------\\n', 'In article <1993Apr10.013011.808@lrc.edu>, burnside_br@lrc.edu writes: >In article <1993Apr6.225034.7184@opencon.com>, giand@opencon.com (Deepak S. Gia nchandani) writes: >> Mubashir Cheema: >> >>      Don\\'t buy one, that is the best way to avoid tickets, >>      I used to have one and whenever a cop would pull me over, see >>      the thing, give me a ticket.  One time my sister was driving, >>      and had it in the glove compartment, it was broken, and she >>      got a ticket.  In 1987, I had received 4 tickets because of >>      it, one for my sister (so a total of five). >> >>      That was five years ago, now I don\\'t have one and Have not >>      gotten a ticket.  My driving habits have not changed >>      drastically.  Only two days ago I was going 77 MPH on Highway >>      with 55 MPH limit, cop saw me, I break a little, nothing >>      happened (I was driving a Mini-Van, with my family in it). >>      Otherwise, I have Cutlass Supreme,  which I do 70 most of the >>      times on the highway. >> >>      So basically my opnion is not to get one, if you do get pulled >>      over, The cop will hear your excuse, but if you have a radar >>      detecter, he will NOT. (again, this has been my experienc >Just get a remote model that is not visible to the cop.  But, be sure to get >front AND rear sensors... You can also just put the detector off to the side on the dash so the cop doesn\\'t see it right away...Valentine is the best detector by far (as stated by Car and Driver) and even tells you what direction the radar is coming from.  It also gives the amount of \"threats\" it is picking up, so if you go through  the same place everyday, and it always goes off there, you can glance at the  number of \"threats\" the Valentine is detecting to see if it is a genuine cop.   It\\'s about $300 and you can only get it factory direct..one problem.                                             Rob Fusi                                             rwf2@lehigh.edu -- \\n', \"In article <1993Apr16.153330.12087@hpcvca.cv.hp.com> scott@hpcvccl.cv.hp.com (Scott Linn) writes: >While playing around with my Gateway 2000 local-bus machine last >night, it became apparent that Windows 3.1 didn't give the option >for 32-bit access for virtual memory. >I am using a permanent swap file, and the disk drive is on the local >bus interface. >Is this expected, or should I be investigating further why no 32-bit >option appears? you  need to massage few switches in your system.ini. in the virtual memory section, flip the 32bitaccess switch on and the  associated driver (wdctl or some such) switch on.  this will enable 32bit access, but be sure you can use it, as not all hard drives and controllers support it !   ...for seriously fast disk access: 1)  throw out WINDOZE 2)  install OS/2 i did this weekend - OS/2 is incredible.  finally a REAL OS for the humble PC  :) --  tim\\n\", 'In article <mdonahue.15x9@amiganet.chi.il.us> mdonahue@amiganet.chi.il.us (Mike Donahue) writes: >As for Adcoms Mobil, They are going with amps that canb use Balanced Inputs, a >VERY nice toy, but I\\'m afraid its goig to push their amps beyound resonable >price ranges.  especialy because taking advantage of those balanced inputs >requires a $120+ RCA to Balanced adapter... Umm, when I was doing sound reinforcement for a living, I used to get direct boxes (which convert unbalanced 1/4\" jacks to balanced XLRs) for about $25 each, or a little more for higher quality. You\\'ll need two for a stereo signal, of course, and a little adapter thingy from  Radio Sh#$&^t to convert from RCA to 1/4\". Total cost should be around $50. You can also buy transformers for quite a bit less and wire them yourself. Total cost there should be under $30. You can get all this stuff from any pro music shop that sells sound reinforcement gear. The benefit? NO noise that you can hear will be generated in the cables going to the component with the balanced inputs, even when you run them in bad places, like next to power lines. ----- John Bell NASA Langley Research Center bell@hops.larc.nasa.gov\\n', 'In article <1993Apr18.175802.28548@clpd.kodak.com> Rich Young, young@serum.kodak.com writes: Stuff deleted >\\t ... have to >\\t consume unrealistically large quantities of barbecued meat at a >\\t time.\" I have to confess that this is one of my few unfulfilled ambitions. No matter how much I eat, it still seems realistic. Don Mackie - his opinion\\n', \"I haven't been following the previous HR's.  But there are two, that I saw live that would have to be up there (up where? there!).   1) Rick Monday's HR to bury the Expos in the NL championship in 1981. It was hit off Steve Rogers, who is a RHP and primarily a starter. Why was he used as a reliever when the 'Spos had Reardon and BillLee warming up in the bullpen.  Considering Monday couldn't touch LHP, Lee would have been a safe bet.  He wasn't even doing any drugs at that time (or so he told me and around 50 others on a recent venture into  Montreal.  The blast wasn't the important aspect.  It was the timing. Seventh game, a tie game, and in the top of the 9th.  The Expos almost came back though... 2) Mike Schmidt hit one that killed the Expos in 1980.  So close, yet, so far. and 3) Strawberry killed a pitch on the second day of the season a couple of years ago.  It went off the technical ring in the Big O.  It almost left the stadium!  That was hit HARD!!! \\t\\t\\t\\tCorelMARK! \\n\", \"In article <2680@emoryu1.cc.emory.edu> libwca@emory.edu (Bill Anderson) writes: -> : \\tAccording to a ``CNN Poll'' to key reason for Clinton's low -> : approval rating is people are angry about him not moving fast enough -> : on gays in the military.  I just burst out laughing when I heard this; -> : what planet do these CNN people live on anyway? -> : -- -> : Jason C. Austin -> : j.c.austin@larc.nasa.gov        ->  -> Dunno, man... that sounds pretty damned unlikely to me, too, -> although it's certainly one of the reasons I'm pissed off at him. -> Maybe the sample was taken entirely from my fellow memebers of the -> Cultural Elite? ->  -> Jason, can you quote some of these poll questions? ->  -> Thanks, -> Bill -> v \\tI've never seen CNN give out the poll questions on the air. If you sent them a letter asking for them, you might get them.  Here's my guess of how part of a session might look: fast enough on gays in the military. \\tI think any group truly dedicated to reporting the news would not use manufactured news like polls. \\t\\t\\t\\t\\t\\t-Jason\\n\", \"In a previous article, rrn@po.CWRU.Edu (Robert R. Novitskey) says: >Just a qestion for all you pc-er's out there.  Will the upcoming pentium >systems be compatible with current simms and vlb cards?  Any info would be >helpful.  I would just like to know before I plunk my $ on new hardware. >Thanks >BoB Well, it all depends on the motherboard implimentation. I'm sure someone will make a vlb motherboard that takes 1x9 simms and uses a pentium processor.  I'm also sure that there  will be some motherboards that won't. -- \\n\", '----------------------------Original message----------------------------                                                                     D\"SB Mincha, Tish(a Yamim La(Omer, Yom Chamishi, Y\"D b\\'Nisan ThShN\"G; Universita Varsha b\\'Varsha, Galut HaMara Meod. SHALOM ALL! Those of You visiting The Ghetto City these days might be interested in the following events timetable  (abridged): 19:00, Fri., 16th April, \\'93: Kabbalat Shabbat service at the Nozyk Shul                                 (6 Twarda Street, Warsaw -- a 10 mins\\'                                 walk from the Palace of Science &                                 Culture: the tallest building in the                                 city\\'s centre, & the same distance from                                 the Central Railway Station). 09:30, Sat., 17th April,  \" : Shacharit L\\'Shabbat service, Nozyk Shul. 11:30, Sun., 18th April,  \" : The Fallen Ones Memorial service, Nozyk Shul. 13:00, Sun., 18th April,  \" : Memorial Ceremony at the Jewish Cemetery                                 (Okopowa Street, Warsaw). 18:00, Sun., 18th April,  \" : Official Arts Programme at the Congress Hall                                 (a building adjacent to the Palace of                                 Science & Culture, which -- like the Shul                                 -- is located a quarter\\'s walk from most of                                 downtown hotels: Bristol, Forum, Victoria,                                 Europejski, Holiday Inn, Marriott). 12:00, Mon., 19th April,  \" : Laying of Wreaths at the Ghetto Heros                                 Monument. Shabbat Shalom UL\\'Hitraot B\\'Varsha! Shelomoh*Slawek*ZIENIUK, student, Univ. of Warsaw (Dept. of Hebrew), Warsaw. ani shalom v\\'khi adaber           hema lamilchama: -- Tehillim Q\"K:Z\\' Guest e-mail account: <27916070@plearn.bitnet>\\n', 'In article <C51puA.K2u@mailer.cc.fsu.edu>, dlecoint@garnet.acns.fsu.edu (Darius_Lecointe) writes: > \"David R. Sacco\" <dsav+@andrew.cmu.edu> writes: > >    Not to be too snide about it, but I think this Christianity must > >    be a very convenient religion, very maliable and suitable for > >    any occassion since it seems one can take it any way one wants > >    to go with it and follow whichever bits one pleases and > >    reinterpret the bits that don\\'t match with one\\'s desires.  It > >    is, in fact, so convenient that, were I capable of believing > >    in a god, I might consider going for some brand of Christianity. > >    The only difficulty left then, of course, is picking which sect > >    to join.  There are just so many. > >      > >    Dean Kaflowitz > >  > > Yes, Christianity is convenient.  Following the teachings of Jesus > > Christ and the Ten Commandments is convenient.  Trying to love in a > > hateful world is convenient.  Turning the other cheek is convenient.  So > > convenient that it is burdensome at times. >  > Some Christians take a 10% discount off the Ten Commandments.  Sunday > cannot be substituted for the Sabbath. Make that 20%.  Where did I see that poll recently about the very religious and adultery?  Was it this newsgroup or alt.atheism or some other place? Dean Kaflowitz\\n', \"I'm looking for any leads to the source of a good Windows Meta File converter or interpreter. I need this for use outside the Windows environment. PD sources preferred, but not a requirement. Please reply to the address below. David Buchholz               Internet: buck@ileaf.com Product Manager                  uucp: uunet!leafusa!buck Interleaf, Inc.                 voice: 617.290.4990 x-3252\\n\", 'In article <1993Apr18.171148.6367@abo.fi> MLINDROOS@FINABO.ABO.FI (Marcus  Lindroos INF) writes: >Later on, the Andersons tried to shed their reputation as creators of some >of the worst pseudo-scientific shows in TV history by flying \"Into Infinity.\" >This was a one-off thing done as part of BBC\\'s \"educational SF\" series \"The >Day After Tomorrow.\" The Anderson episode dealt with a spaceship capable of >reaching the speed of light (\"lightship Altares\"), the four-man crew  >eventually journeyed into a black hole and ended up on the far side of the  >galaxy (I think). I saw this as a 9-year-old back in 1976 and liked it very  >much, but then again I was a fan of SPACE:1999 so I guess I was easily  >satisfied in those days:-) Wow.  I was beginning to think that I had made that up.  I remember that movie (it was about 1.5 hours long).  I don\\'t think they ended up anywhere in the known universe.   I remember they got a message halfway out to Proxima Centauri, that Earth transmitted a day after they launched, timed to catch up with them at the halfway point.  I thought it was neat, I think I was all of 10 at the time. >Does anyone know if \"Into Infinity\" has been released on video? I have some >SPACE:1999 shows on VHS and know that Thunderbirds etc. also are available in >England. I will look for the Into Infinity show, I never did know that was the name of it, I thought the show was called \"the day after tomorrow\", and that was it. --  If you blow fire against the wind, take care to not get the smoke in your eyes.       Big & Growly Dragon-monster        |        bafta@cats.ucsc.edu    --------> shari brooks <--------      |    brooks@anarchy.arc.nasa.gov                       The above opinions are solely my own.\\n', '  The dead giveaway is the repeated protestations that the new plan is aimed at \"criminals\", \"drug dealers\", \"terrorists\", etc.  You\\'d think the tactic would be too obvious to trot out yet again after a decade of Sarah and the rest of the Brady Bunch using it to destroy the Second Amendment, but evidently the control nuts feel it will serve them one more time.   As far as the export needs of American companies are concerned, I could almost believe that the plan to saddle the US industry with a hidden sabotaged algorithm was invented by a cabal of Japanese lobbyists.\\n', \"egaillou@etu.gel.ulaval.ca (Eric Gailloux) writes: >I'm about to purchase a laser printer for my Mac and I read the MacUser >Buying Guide special issue. All HP printers (except IIISI) are rated very low >compared to other noname bargain-priced printers. Why is that so? On the PC, >HP printers are THE standard amongst printer manufacturers. >PS: My personnal favorite -budgetwise- would be the IIIP. The IIIP has just been superseded by the 4M, which is the one I am using at work.  The quality of the print is execellent, beating 300 dpi printers hands down.  In Australia the price of the 4M is about comparable with that of the III-series, so HP are trying to get people to buy the new one !!! Anthony Pun anthonyp@extro.ucc.su.oz.au\\n\", \"I am in the midst of designing a project which requires two motors and an LED illuminator driven with Pulse-width modulation.  I'm using the 8751, and I understand that the -FB version has a programmable counter array that can essentially be set and forgotten to do the PWM.  The problems is, that variant is difficult to come by.  I need two or three of the D prefix (ceramic window) version for development, and then lots of the P prefix (plastic OTP) for later production.  I've tried Avnet, Arrow, and Pioneer.  They (might) have them, but I'm looking for samples at this point, and they're not too willing to provide them.  I would buy them, but these vendors have $100.00 minimums. Any help is appreciated. ================================================================================ [ Mark E. Levy, Fermilab          |                                            ] [ BitNet:   LEVY@FNAL             | Unix is to computing                       ] [ Internet: LEVY@FNALD.FNAL.GOV   |       as an Etch-a-Sketch is to art.       ] [ HEPnet/SPAN: FNALD::LEVY (VMS!) |                                            ] ================================================================================\\n\", ' <93104.173826U28037@uicv <PA146008.711.734832476@utkvm1.utk.edu> In article <PA146008.711.734832476@utkvm1.utk.edu>, PA146008@utkvm1.utk.edu (David Veal) says: >> [stuff deleted] >>What seems to be happening here is the situation getting totally blown out of >>proportion.  In my post I was referring to your regular patrolman in a car >>cruising around the city vs. gang members.  Of course the police have access >>to the things that you mentioned but do they use tanks and such all of the >>time?  Of course they don\\'t and that\\'s the point I was trying to make.  Every >>day when I go out to lunch I always see cops coming in.  The majority that I >>see are still carrying revolvers.  Not that there is anything wrong with a >>revolver but if you\\'re a cop that is up against some gang member with a >couple >>of automatics in his coat (I mean semi-auto handguns) you\\'re going to be at a >>disadvantage even with training. >      This is the \"arms race\" fallacy.  That somehow bigger guns make an >individual safer.  The problem is that for each corresponding level of >offensive power the is not an automatic level of defense increase.  The >problem is that there\\'s a sort of lethality threshold that once you get >past you\\'re only talking about a metter of degree. >      Regardless of what cops are up against there\\'s really no reason >for the average beat cop to have anything bigger than a pistol on him >as a personal weapon and maybe a rifle and a shotgun in the cruiser. >      I mean, think about it.  Carrying a monster pistol or sub-machinegun >doesn\\'t make the cop any less wounded if somebody shoots him.  A lot >of police departenments have switched to semi-automatics, as better >more reliable weapons, and more stopping power, but there\\'s a point >of diminishing returns. This is a very, very good point.  Who cares what kind of gun you\\'ve got if you\\'re lying on the ground dead. >      And as far as automatics go, any gang member carrying around \"a >couple\" of automatics (an incredible rarity) is going to be far more of >a menace to himself and innocent bystanders than anything he might be >tryinh to aim at.  One auto is hard enough to control.  Anybody who >could control two is going to get the police officer regardless of >what the police officer is armed with. [more stuff deleted.  mostly mine] >        My question is this:  What would a police officer gain from >having a sub-machinegun or similar personal weapon that he already >doesn\\'t have with a 9mm or 10mm semi-automatic pistol?  I don\\'t see >as how the police should be hosing around full-auto fire, nor has >my experience with police officers (or the stats regarding how many >police officers get killed by other cops) made me feel such would be a >good idea.  Precise fire is far more preferable.  Nor should they using >\"bigger\" guns.  Most standard sidearms have more then sufficient >stopping power when properly applied.  All more powerful weapons would >do is make the likelihood of death higher without really giving police >significantly more options. Another very good point that is well taken.  It seems that when lots of lead is flying (either the cops or the gangs) someone innocent always gets caught in the crossfire. >------------------------------------------------------------------------ >David Veal Univ. of Tenn. Div. of Cont. Education Info. Services Group >PA146008@utkvm1.utk.edu - \"I still remember the way you laughed, the day >your pushed me down the elevator shaft;  I\\'m beginning to think you don\\'t >love me anymore.\" - \"Weird Al\" All points made above are well taken.  I guess I am in the mindset of \"having more makes it better\" which is obviously not the correct mindset to take in this discussion.  Now that I think about the situation a little more carefully I see your point exactly David and I wholeheartedly (sp?) agree.  Like I said I\\'m just assuming that \"more bullets and/or bigger bullets is better\".  Once again though I want to state that I am a pro-gun individual and do NOT believe that gun control is really a viable option here in the United States regardless of the drivel that I spout here :-) Jason\\n', 'The following flyer was distributed at AIPAC\\'s 34th annual Policy Conference: Because when we\\'re not in Israel, we\\'re told to go back where we came from and when we come back to Israel we\\'re told to go back to where we came from and  when we\\'re vocal we have too much influence and when we are quiet we can afford to be because we we control everything anyway and when we buy something we can afford to because Jews are so rich and when we don\\'t buy something it\\'s because we\\'re cheap and because when we are poor we\\'re called dirty Jew and ignorant and when we\\'re not we\\'re called called rich Jew and JAP and when we are visibly organized it\\'s because there is a secret Jewish conspiracy and when we\\'re not it is because there is a secret Jewish conspiracy and because we\\'re told we\\'re not a people and when we say we are we\\'re still told that we\\'re not and when we marry our own people we\\'re called racist and we don\\'t we\\'re contaminating  someone else\\'s \"race\" and because we\\'re under fire from the Left and from the  Right and because there are whites who hate us for not being white and because there are non-whites who hate us for being white  and because anti-semitic  incidents are rising every year but we\\'re told that anti-semitism doesn\\'t  exist or that we\\'re paranoid and because we\\'re told to shut up about the  Holocaust and yet Holocaust revisionism is risng every year and when we are \"obnoxious\" we\\'re called JAPs and when we are \"nice\" we\\'re told we don\\'t act Jewish and because anti-semitism is now world-wide and because our people is not yet free and because we do not have to complete the work but neither are we free to desist from it for these reasons and many many more we are part of the Jewish National Liberation Movement: ZIONISM.\\n', ' > Somebody asked me what was wrong about overreacting in cases such as this.  >  > The reason is very simple:  How many people do you want to die in a riot?  >In a new Civil War?   Not me -- which is precisely why the government must be cut off at the knees when it pulls stunts like this, lest the situation worsen to the point where extreme measures are required.\\n', 'Reply to haljordan@delphi.com or call 708 674-2603: U.S. Robotics 16.8 Dual standard, V.32 bis, 14.4k baud, 16.8 hst.  Price: $449.\\n', 'In article <C5nGII.BGx@news2.cis.umn.edu> bunt0003@student.tc.umn.edu (Monthian Buntan-1) writes: >Hi there, >Does anyone know why Apple has an ambiguous message for >C650 regarding fpu?  In all Mac price lists I\\'ve seen, every C650 >has the message \"fpu: optional\".  I know from what we\\'ve discussed in this >newsgroup that all C650 have the fpu built in except the 4/80 >configuration.  Why would they be so unclear about this issue in their >price list? >I\\'m planning to buy the C650 8/230/cd pretty soon, but I\\'m now getting >confused with whether it comes with fpu or not. >Why say \"optional\" if it\\'s built in? >Please, anybody help me understand this game. >Regards, >Thian. If you get the Centris 650 with CD configuration, you are getting a Mac with a 68RC040 processor that has built-in math coprocessor support.  My  understanding is that the \"optional fpu\" refers to your option of purchasing the Centris 650 4/80 without FPU OR one of the other configurations WITH FPU. Apple does not offer an upgrade from the non-FPU system to become an FPU system.  And, it is unclear whether the \\'040 processor on the non-FPU system (a 68LC040) can be replaced with a 68RC040 supplied by another vendor. Apple did send a memo out at one point sating that the Centris 610, which ONLY comes with a non-FPU 68LC040 processor CANNOT be upgraded to support an FPU - the pin configurations of the two chips apparently do not match so you cannot swap one for another (again, according to Apple\\'s memo). Hope that helps. Kevin Lohman University Book Store, University of Washington Buyer for the UW Apple Computers for Education Program\\n', 'In article <UfnYJ2a00VoqIT9VpA@andrew.cmu.edu> nm0w+@andrew.cmu.edu (Nanci Ann Miller) writes: >jcopelan@nyx.cs.du.edu (The One and Only) writes: >> Welcome.  I am the official keeper of the list of nicknames that people >> are known by on alt.atheism (didn\\'t know we had such a list, did you). >> Your have been awarded the nickname of \"Buckminster.\"  So the next time >> you post an article, sign with your nickname like so: >> Dave \"Buckminster\" Fuller.  Thanks again. >>  >> Jim \"Humor means never having to say you\\'re sorry\" Copeland >Of course, the list has to agree with the nickname laws laid down by the >GIPU almost 2000 years ago (you know... the 9 of them that were written on >the iron tablets that melted once and had to be reinscribed?).  Since I am >a prophet of the GIPU I decree that you should post the whole list of >nicknames for the frequent posters here! If the first rule of humor is never having to say you\\'re sorry then the  second rule must be never having to explain yourself.  Few things are  worse that a joke explained.  In spite of this, and because of requests for me to post my list o\\' nicknames, I must admit that no such list exists.  It was simply a plot device, along with me being the keeper o\\' the list, to make the obvious play on the last name of Fuller and to advance the idea that such a list should be made. I assumed that the ol\\' timers would recognize it for what it is.   Nevertheless, how about a list o\\' nicknames for alt.atheism posters? If you think of a good one, just post it and see if others like it. We could start with those posters who annoy us the most, like Bobby or Bill. Jim \"D\\'oh! I broke the second rule of humor\" Copeland -- If God is dead and the actor plays his part                    | -- Sting, His words of fear will find their way to a place in your heart | History Without the voice of reason every faith is its own curse       | Will Teach Us Without freedom from the past things can only get worse        | Nothing\\n', \"I am posting the following for my brother. Please post your replies or send him email to his address at the end of his message. Thank you. ____________________________________________________________________ My supervisor is looking for a image analysis software for MS DOS. We need something to measure lengths and areas on micrographs. Sometime in the future, we may expand to do some densitometry for gels, etc. We've found lots of ads and info for the Jandel Scientific products: SigmaScan and Java. But we have not been able to find any competing products. We would appreciate any comments on these products and suggestions / comments on other products we should consider. Thanks. Donald UserDONO@MTSG.UBC.CA\\n\", 'A co-worker of mine needs to convert a postscript file to a form readable (ie ascii) in windows or DOS. Does anybody know of a utility that will do this? I have a vague memory of a shareware utility someone mentioned once... Thanks for any info, Barry.\\n', 'After reading the service manual for my bike (Suzuki GS500E--1990) I have a couple of questions I hope you can answer: When checking the oil level with the dip stick built into the oil fill cap, does one check it with the cap screwed in or not?  I am more used to the dip stick for a cage where the stick is extracted fully, wiped clean and reinserted fully, then withdrawn and read.  The dip stick on my bike is part of the oil filler cap and has about 1/2 inch of threads on it.  Do I remove the cap, wipe the stick clean and reinsert it with/without screwing it down before reading? The service manual calls for the application of Suzuki Bond No. 1207B on the head cover.  I guess this is some sort of liquid gasket material.  do you know of a generic (cheaper) substitute? My headlight is a Halogen 60/55 W bulb.  Is there an easy, brighter replacement bulb available?  Where should I look for one? As always, I very much appreciate your help.  The weather in Philadelphia has finally turned WARM.  This weekend I saw lotsa bikes, and the riders ALL waved.  A nice change of tone from what Philadelphia can be like. . . . Chris --  ******************************************************************* Christopher G. Karras\\n', 'What is the deal with life on Mars?  I save the \"face\" and heard  associated theories. (which sound thin to me) Are we going back to Mars to look at this face agian? Does anyone buy all the life theories? --  Don Schiewer   | Internet  schiewer@pa881a.inland.com    | Onward Great Inland Steel   | UUCP:     !uucp!pa881a.inland!schiewer  | Stream...\\n', \"In article <1993Apr13.213527.3706@ultb.isc.rit.edu> snm6394@ultb.isc.rit.edu (S.N. Mozumder ) writes: > How about people who are not religous?  Take the inner city.  There are > many people that care little for religion.  Lot of crime.  Lot of > murder.  This is the other end- lack of religion- that allows wrong to > happen. I lived in Tokyo for a year and a half, and one of the many reasons why I intend to go back indefinitely is the freedom one enjoys when one can walk anywhere (and I mean *anywhere*) at any time of day or night and not feel uneasy, even if one's from an ethnic minority as I was. Clues for Bobby (why do I bother?): (i) Tokyo is a city, and inner Tokyo is an inner city; (ii) there is a negligible level of violent crime, and a street murder will be a lead item on *national* TV news; (iii) the population is almost universally atheistic. Next time I go for a stroll around Beirut at night, I'll let you know how it compares. > Bobby Mozumder Cheers Simon --  Simon Clippingdale                simon@dcs.warwick.ac.uk Department of Computer Science    Tel (+44) 203 523296 University of Warwick             FAX (+44) 203 525714 Coventry CV4 7AL, U.K.\\n\", \"It is meaningless to compare one player's plus/minus statistic with another players' out of the context of the role and the playing time of the players involved.     To compare Jagr's and Francis's plus/minus is ridiculous and absurd... Gerald\\n\", \"In article <1993Apr18.014305.28536@sfu.ca>, Leigh Palmer <palmer@sfu.ca> writes: > In article <C5nGxq.663@zoo.toronto.edu> Henry Spencer, > henry@zoo.toronto.edu writes: > >The National Air & Space Museum has both the prototype and the film. > >When I was there, some years ago, they had the prototype on display and > >the film continuously repeating. >  > Great! I'll visit the National Air and Space Museum at the end of the > month with my wife, who was also working at General Atomic at the time. > Once again netnews has enriched my life. Sorry to put a damper on your plans, but I was there three weeks ago and it wasn't there.  Not that I would have known to look for it, of course, but I combed the space exhibits pretty thoroughly and something like that would have caught my attention instantly. --  This is news.  This is your       |    Peter Scott, NASA/JPL/Caltech brain on news.  Any questions?    |    (pjs@euclid.jpl.nasa.gov)\\n\", 'Comp. Graphics/CAD (cgcad@bart.inescn.pt) wrote: : There is a new version of the RTrace ray-tracing package (8.2.0) at : asterix.inescn.pt [192.35.246.17] in directory pub/RTrace. : Check the README file. cant seem to reach the site from over here: >#ping 192.35.246.17 >ICMP Net Unreachable from gateway nsn-FIX-pe.sura.net (192.80.214.253) >for icmp from ccws-24.brunel.ac.uk (134.83.176.30) to 192.35.246.17 Is it possible for you to upload to a more mainstream ftp place?\\n', 'In article <1993Apr14.231117.21872@pony.Ingres.COM> garrett@Ingres.COM  writes: >In article <philC5Ht1t.GwA@netcom.com>, phil@netcom.com (Phil Ronzone)                   writes... >>Along with normalized relations with the PRC. >\"Normalizing relations\" with Cambodia? You must be joking. We sponsored >the OVERTHROW of the Cambodian government. After repeated failed attempts >of course.  PRC = People\\'s Republic of China != Cambodia.  Go play. --  Dave Griffith, Information Resources, University of Chicago, Department of Surgery                       dave@alex.bsd.uchicago.edu Brain damage was what we were after.  The chromosome damage was just gravy.\\n', 'In article <lsj1gdINNkor@saltillo.cs.utexas.edu> turpin@cs.utexas.edu (Russell Turpin) writes: >-*---- >How does the helium get consumed?  I would have thought that failure >to contain it perfectly would result in its evaporation .. back into  >the atmosphere.  Sounds like a cycle to me.  Obviously, it takes  >energy to run the cycle, but I seriously doubt that helium consumption >is a resource issue. It\\'s not a cycle.  Free helium will escape from the atmosphere due to its high velocity.  It won\\'t be practical to recover it.  It has to be mined. --  ---------------------------------------------------------------------------- Gordon Banks  N3JXP      | \"Skepticism is the chastity of the intellect, and geb@cadre.dsl.pitt.edu   |  it is shameful to surrender it too soon.\"  ----------------------------------------------------------------------------\\n', 'In article <C5K7nK.7tv@news.cso.uiuc.edu> rkoffler@ux4.cso.uiuc.edu (Bighelmet) writes: >csc2imd@cabell.vcu.edu (Ian M. Derby) writes: >>Since someone brought up sports radio, howabout sportswriting??? >I happen to be a big fan of Jayson Stark.  He is a baseball writer for the  >Philadelphia Inquirer.  Every tuesday he writes a \"Week in Review\" column.   >He writes about unusual situations that occured during the week.  Unusual >stats.  He has a section called \"Kinerisms of the Week\" which are stupid >lines by Mets brodcaster Ralph Kiner.  Every year he has the LGTGAH contest. >That stands for \"Last guy to get a hit.\"  He also writes for Baseball  >America.  That column is sort of a highlights of \"Week in Review.\"  If you  >can, check his column out sometime.  He might make you laugh. >Rob Koffler Isn\\'t Stark that idiot who writes in Baseball America?   Twice a month he writes a \"Who woulda thunk it\" article which is really the same piece every time.   \"Who would have thought that [Buddy Biancalana] would have more home runs than [the Colorado Rockies, Babe Ruth, Omar Vizquel and Nolan Ryan] COMBINED!\"   He\\'s an idiot, if it\\'s the same guy. >--  >****************************************************************** >|You live day to day and                rkoffler@ux4.cso.uiuc.edu| >|dream about tomorrow --Don Henley                               | >****************************************************************** Andrew\\n', 'Hi. While running the MS Quick C compiler in a DOS window under Windows 3.1  this evening, I got a \"program has violated system integrity... close all  applications, exit windows and restart your computer\" error. I started to do this when I immediately got a \"Serious disk error\" message from Windows.  \"hit return to retry\".  I did that about 5 times and then rebooted to find that quite a few files have been corrupted somehow. (I am including the chkdsk output below.) 1)  Is there an easy way to restore everything to working order? What might be some better approaches? 2)  What might have caused this?  Does the SMARTDRV cache make me more vulnerable?  (I\\'m suspicious of hard drive caches especially when they cache data writing.) The straightforward approach would be to run chkdsk with the /f option to  fix the disk and then it looks like I would probably have to reinstall Windows and a few other things. Thanks for your comments and suggestions. Brad Banko chkdsk output: ====================================================================== Volume Serial Number is 1159-09D3 Errors found, F parameter not specified Corrections will not be written to disk    Allocation error, size adjusted    Allocation error, size adjusted    Allocation error, size adjusted    Allocation error, size adjusted    Allocation error, size adjusted    Allocation error, size adjusted    Allocation error, size adjusted    316 lost allocation units found in 224 chains.     647168 bytes disk space would be freed    Is cross linked on allocation unit 16133    Is cross linked on allocation unit 16138    Is cross linked on allocation unit 16139    Is cross linked on allocation unit 16140    Is cross linked on allocation unit 16141    Is cross linked on allocation unit 16146    Is cross linked on allocation unit 16151    Is cross linked on allocation unit 16152    Is cross linked on allocation unit 16153    Is cross linked on allocation unit 16154    Is cross linked on allocation unit 16155    Is cross linked on allocation unit 16156    Is cross linked on allocation unit 16157    Is cross linked on allocation unit 16208    Is cross linked on allocation unit 16184    Is cross linked on allocation unit 16185    Is cross linked on allocation unit 16186    Is cross linked on allocation unit 16187    Is cross linked on allocation unit 16188    Is cross linked on allocation unit 16189    Is cross linked on allocation unit 16190    Is cross linked on allocation unit 16191    Is cross linked on allocation unit 16199    Is cross linked on allocation unit 16201    Is cross linked on allocation unit 16382    Is cross linked on allocation unit 16380    Is cross linked on allocation unit 16367    Is cross linked on allocation unit 16341    Is cross linked on allocation unit 16151    Is cross linked on allocation unit 16257    Is cross linked on allocation unit 16339    Is cross linked on allocation unit 16184    Is cross linked on allocation unit 16201    Is cross linked on allocation unit 16257    Is cross linked on allocation unit 16265    Is cross linked on allocation unit 16275    Is cross linked on allocation unit 16339    Is cross linked on allocation unit 16133    Is cross linked on allocation unit 16146   42366976 bytes total disk space    3958784 bytes in 4 hidden files     153600 bytes in 67 directories   36042752 bytes in 1496 user files    1564672 bytes available on disk       2048 bytes in each allocation unit      20687 total allocation units on disk        764 available allocation units on disk     655360 total bytes memory     579712 bytes free --  Brad Banko;  Dept of Physics;  U of Illinois;  b-banko@uiuc.edu ========================================================================= See one.  Do one.  Teach one.\\t\\t\\t73 de kb8cne @ n9lnq.il\\n', 'I am a new reader of sci.crypt I would like to obtain a copy of a public domain program that can encrypt files, preferably using DES, that runs under MS-DOS. I would also like to obtain a program which will password protect floppy disks, if this is possible. Thanks. David Maddison Melbourne, Australia\\n', \"In <1993Apr19.193758.12091@unocal.com> stgprao@st.unocal.COM (Richard Ottolini) writes: >Beware.  There is only one such *copyrighted* image and the company >that generated is known to protect that copyright.  That image took >hundreds of man-hours to build from the source satellite images, >so it is unlikely that competing images will appear soon. So they should sue the newspaper I got it from for printing it. The article didn't say anything about copyrights. Louis --  I'm hanging on your words, Living on your breath, Feeling with your skin, Will I always be here?  -- In Your Room [ DM ]\\n\", 'shag@aero.org (Rob Unverzagt) writes: >In article <5APR199318045045@kelvin.jpl.nasa.gov> baalke@kelvin.jpl.nasa.gov (Ron Baalke) writes: >> According the IAU Circular #5744, Comet Shoemaker-Levy 1993e, may be >> temporarily in orbit around Jupiter.  The comet had apparently made a >> close flyby of Jupiter sometime in 1992 resulting in the breakup of the >> comet.  Attempts to determine the comet\\'s orbit has been complicated by >> the near impossibility of measuring the comet\\'s center of mass. >> >Am I missing something -- what does knowing the comet\\'s center >of mass do for you in orbit determination? >Shag I\\'m not sure, but it almost sounds like they can\\'t figure out where the  _nucleus_ is within the coma. If they\\'re off by a couple hundred miles, well, you can imagine the rest... -- Phil Fraering         |\"Seems like every day we find out all sorts of stuff. pgf@srl02.cacs.usl.edu|Like how the ancient Mayans had televison.\" Repo Man\\n', \"In article <1r19l9$7dv@usenet.INS.CWRU.Edu> oldham@ces.cwru.edu (Daniel Oldham) writes: :What happened in Waco is not the fault of the BATF. If they would of :had the proper equipment and personal then they could of captured the :With the WoD and the increased crime in the streets the BATF is needed :more now then ever. If they blast away a few good fokes then that is :With the arms build up in Waco they needed to hit that compound with :mega fire power. They could of gone in there blasting and killed a few I hope this is a joke... if not, here's my response: The BATF has a history of no-knock raids with poor evidence, often resulting in innocent people being killed or suffering injury to person or property.  I will NOT support the BATF until they clean up their act... Maybe...  As to equipment, the BATF has damn near anything it wants...  Their faults were in intelligence (military and civilian definitions apply), tactics (attacking during DAYLIGHT??), methodology (the FBI stated that it is against government policy to assault a position where there are non-combatants/potential hostages without attempting negotiations first), and legality.  The BATF's jurisdiction is TAXES on firearms and tobacco.  They are a branch of the department of the treasury.  They have very curiously backed away from their claims of illegal weaponry to push the child-abuse charges... The BATF has no jurisdiction over non-firearms/tobacco issues! And the charges of child-abuse had been investigated in the past with no violence and no validation.  This was a clear case of first the BATF, then the FBI, having watched too many Rambo movies...  My opinion is that the agent in charge should be charged with executing an illegal raid, criminal negligence, murder, civil rights violations, and breaking his/her oath to uphold and defend the Constitution of the US.  The warrant should be unsealed to reveal to the  public what justification the BATF thought it had in committing an armed assault on American citizens.  And while on the issue of investigating this issue, the Randy Weaver case and the Johnny Lawmaster case should be investigated for BATF wrongdoing. James btw, if the BATF came busting in my windows with concussion grenades, you could damn well bet I would return fire to the utmost of my ability. --  ******************************************************************************** James S. Cochrane        *  When in danger, or in doubt, run in * This space  gt6511a@prism.gatech.edu *  circles, scream and shout.          * for rent ********************************************************************************\\n\", \"Salutations! \\tI don't usually subscribe to these newsgroups so I would really appreciate it if someone could possibly e-mail me the answer to my problem. I have been using Windows 3.1 since buying it last winter but I have just now come across an annoying bug. I now have about 8 different groups in program manager but it seems that everytime I install something new that makes a new group, it promptly disappears after I turn of windows! This happened when I installed Excel and WinFax Pro v.3. They both created their own groups but when I turned off windows and reran them, they were gone. I had to manually pull them up as new items and put them in a previously existing group as all new gropus disappear as soon as I turn off windows. \\tmy set up: \\t\\t\\tprecision 386dx-25 w/ 4 megs \\t\\t\\tTrident 8900c with 1 meg  \\t\\t\\tWindows 3.1 running in 800x600 colour mode \\t\\t\\tlogitech mouseman \\t\\t\\t Thank you in advance! Emile Woo ewoo@unixg.ubc.ca --  ------------------------------------------------------------------------------ Emile Woo, Student Representative to Senate |  .sig unavailable. Holding \\n\", 'In article <93111.225707PP3903A@auvm.american.edu> Paul H. Pimentel <PP3903A@auvm.american.edu> writes: >What gives Isreal the right to keep Jeruseleum?  It is the home of >the muslim a s well as jewish religion, among others. \\tIsrael has a right to keep Jerusalem for many reasons.  They include the fact that the majority of the citizens are Israeli, the fact that Israel maintains religious freedom for all people, and the historical connection of Judaism to Jerusalem. \\tWhen Jerusalem was devided by a Jordanian invasion in 1948, the cease fire agreement included the right of individuals to visit religious shrines.  This cease fire agreement was violated by Jordan, who did not allow Jews to visit holy sites under their control.  The Jordanians also bulldozed every synagoge in the city.  They turned a Jewish cemetary into a hotel, and used the gravestones in their latrines. \\tIsrael has allowed individuals of all religions into Jerusalem, protected holy sites, and demonstrated its fitness to control the city. \\tAlso, I should point out that Islam is not centered in Jerusalem, but has holy sites there.  The home of Islam is Mecca, where all Muslims should make a pilgramage (the hajj).  Unlike Israeli Jerusalem, Jews and Christians are not allowed in Saudi Mecca. Adam Adam Shostack \\t\\t\\t\\t       adam@das.harvard.edu \"If we had a budget big enough for drugs and sexual favors, we sure wouldn\\'t waste them on members of Congress...\"   -John Perry Barlow\\n', \"From article <1rc07h$ern@olivea.ATC.Olivetti.Com>, by manu@oas.olivetti.com (Manu Das): >  > I have a overlapped window(say V) which has few child windows (a,b,c, etc) > The window shows up with all it's children fine. Now, I create another  > child(t) with a WS_THICKFRAME style and placed on top of one or more of > it's siblings. Style WS_THICKFRAME is used so that I can resize it. How do > I make sure that the child 't' will always be at the top of it's siblings. > I used SetWindowPos() and BringWindowToTop() without success. What's happening > is that while I am resizing 't' it shows up but as soon as I let go, it goes > behild it's siblings. The window is probobly on top but the lower windows are drawing over it. Try using WS_CLIPSIBLING to keep the lower siblings from drawing on the top sibling's space. --  Ed ekalenda@netcom.COM\\n\", 'Does anyone have any experience using LCIII with MIDI?  Do they get along OK? I have heard that the IIvx is not suitable for MIDI, but I have not heard anyon e say anything definitive about LCIII and MIDI?  If you have had experience, wh at MIDI interface have you used?  Anyone used Finale software in this setting?  Please e-mail.  I will summarize. Thanks, Jerry Bartlett Peoria, Illinios u56149@uicvm.cc.uic.edu\\n', \"AllMartin EmdeDMM Advice Needed ME>From: mce5921@bcstec.ca.boeing.com (Martin Emde) ME>Organization: Boeing ME>  ME>I an currely in the market for a DMM and recently saw an add ME>for a Kelvin 94 ($199).  Does anyone own one of these or some ME>other brand that they are extremely happy with.  How do the  ME>small name brands compare with the Fluke and Beckman brands? ME>I am willing to spend ~$200 for one. ME>  ME>Any help is greatly appreciated. (please email) ME>  ME>-Martin If you are going to use one where it counts (eg:aviation, space scuttle,  etc) then I suggest you go and buy a Fluke (never seen a Beckman), however  for every other use you can buy a cheapie. I have a metex which is some  made up name, as I have seen the same DMM with other brand names on it, I  bought it about 4 yrs ago for Aus$125.00 (convert that to US and you see  that it's definetly a cheapie.) So far it has proved to be accurate, taken  moderate abuse, and has many features on it (CAP, FREQ,Transistor check,  etc). I am very happy with it and would definetly not buy a fluke just for  the name. Hope this helps. Cheers  Peter T.\\n\", \" <1993Apr19.201300.27080@CSD-NewsHost.Stanford.EDU> In article <1993Apr19.201300.27080@CSD-NewsHost.Stanford.EDU>, andy@SAIL.Stanford.EDU (Andy Freeman) says: >Clue - Kratz' position isn't a defense against inaccuracy. >I oppose gun control because it doesn't work.  If it did, I'd support >it.  In fact, I supported gun control before I did my homework. >There's no demand for pro-gun people who don't know what they're >talking about.  In fact, they'd be much better off if they didn't say >anything. And why is this Freeman?  Even if a pro-gun person doesn't know what they are talking about there is always the possibility that they will learn a thing or two.  I am and will continue to post even if people get angry with what I have to say.  I have several good sources of material now that I know where to look so calm down. >There's lots of information flowing on tpg for those interested in >learning.  One can participate in those discussions without ranting >inaccurately.  Failure to do so has consequences. Ah, Freeman seems to forget from my statement that I am learning.  I have also asked several of the not-so-hostile folks on this group for sources of information to read.  Do you think, Freeman, that maybe this means I am interested in learning?  I think it does because as you said people who don't know anything won't be good for the pro-gun cause. >Another good habit to get into is to go read-only for a while, to take >the time to figure out how things work. Another good habit to get into is to realize that not everyone is you Freeman and accept mistakes.  Sure, maybe it could have been some type of misinformation being slung by some anti-gun nut but it wasn't.  I made my statement to inform everyone of this and everyone who replied said don't worry about it but also to learn as much as you can.  They accepted my mistake and gave me sources of information and told me to read as much as possible.  I have read several posts of yours and have found them informative.  Why don't you give me the same chance? >-andy Jason\\n\", \"With all the talk about this Clipper chip, I have developed one question... \\t\\t\\tHOW DOES IT WORK??? If you use this, then how does it get decrypted on the other end? Does the other party (receiving the phone call/mail/etc) have to know some code to  undo it? Do I use a different method for calling one party than I would for  another?. If the other party can decrypt it, doesn't that mean that someone else could also? I assume that if everyone has a different key, the only use would be storing secure data for later retrieval by the same key. This seems like a fundamental question to me, but I have very little experience with cryptosystems, other than DES. If someone could give me an explanation as to how it would be used (remember that I have had little experience with this sort of thing) it would be very much appreciated.  \\t\\t\\t\\t\\tJustin York \\t\\t\\t\\t\\tjyork@iastate.edu\\n\", 'I was reading Popular Science this morning and was surprised by an ad in the back.  I know that a lot of the ads in the back of PS are fringe science or questionablely legal, but this one really grabbed my attention. It was from a company name \"Personal Missle, Inc.\" or something like that. Anyhow, the ad stated that they\\'d sell rockets that were up to 20\\' in length and engines of sizes \"F\" to \"M\".  They also said that some rockets will reach 50,000 feet. Now, aside from the obvious dangers to any amateur rocketeer using one of these beasts, isn\\'t this illegal?  I can\\'t imagine the FAA allowing people to shoot rockets up through the flight levels of passenger planes. Not to even mention the problem of locating a rocket when it comes down. And no, I\\'m not going to even think of buying one.  I\\'m not that crazy. -Paul \"mine\\'ll do 50,000 feet and carries 50 pounds of dynamite\" Dokas --  #include <std.disclaimer> #define FULL_NAME                          \"Paul Dokas\" #define EMAIL                              \"pbd@runyon.cim.cdc.com\" /*            Just remember, you *WILL* die someday.             */\\n', \"In article KKq@acsu.buffalo.edu, v128r82w@ubvmsd.cc.buffalo.edu (Ralph L d'Ambrosio) writes: >In article <1993Apr14.015415.10176@mprgate.mpr.ca>, tasallot@galaxy.mpr.ca (Mathew Tasalloti) writes... >>  >>If the Penguins get out of the Patrick, they will win the >>cup.  However, their hardest task is to get out of that division. >>I'm sure that Washington will most definitly throw a rench into the >>Penguin plans.  I'm a Canucks fan (not that I think much of their >>chances this year), but it seems to me like Washington is the ONLY >>team that can stop the Penguins from winning their next Stanley Cup. >I was under the impression that the Penguins has had the Caps number for  >most of the season. >>  >>  >>  >>=============================================******>> >>  >>  Mathew Tasalloti >>  MPR Teltech Ltd. >>  Vancouver, BC, Canada     >>  >>              <<******================================================== >******************************************************************************** >Of course no one asked me, I always interject my opinions on matters I have no >concern over. >-------------------------------------------------------------------------------- >Go Islanders, Playoffs here we come >Go Jets for '93 >******************************************************************************** And last year the Capitals had the Pens number up until about game 3 of the playoffs. John Horstmann\\n\", 'Jeff.Cook@FtCollinsCO.NCR.COM (Jeff Cook) writes: ... >people in primitive tribes out in the middle of nowhere as they look up >and see a can of Budweiser flying across the sky... :-D Seen that movie already. Or one just like it. Come to think of it, they might send someone on a quest to get rid of the dang thing... >Jeff Cook                                  Jeff.Cook@FtCollinsCO.NCR.com -- Phil Fraering         |\"Seems like every day we find out all sorts of stuff. pgf@srl02.cacs.usl.edu|Like how the ancient Mayans had televison.\" Repo Man\\n', 'In article <93087.011308PXF3@psuvm.psu.edu> PXF3@psuvm.psu.edu (Paula Ford) writes: >A friend of mine was a regular volunteer blood donor.  During surgery, he >was given five units of blood, and after a suitable recovery time, he went >to donate blood at a \"bloodmobile.\" He was HIV+, and did not know it. >The Red Cross notified him with a _registered letter_.  That\\'s all.  No >counselling, no nothing.  He died two years ago, this week.  He left behind How long ago was this?  When I said you\\'d get counselling, I meant if you did it now.  Long ago, practices varied and agencies had to gear up to provide the counselling. >a wife and a four-year-old son.  Many people have suggested that his wife >should sue the Red Cross, but she would not.  She says that without the >blood transfusions he would have died during the surgery. Good for her.  What we don\\'t need is everyone suing community service agencies that provide blood that people need.  Testing is not fool proof. The fact that he got AIDS from a transfusion (if he really did) does not mean the Red Cross screwed up.  Prior to 1983 or so, there wasn\\'t a good test and a lot of bad blood got through.  This wasn\\'t the fault of the Red Cross.  When did he get the transfusions? --  ---------------------------------------------------------------------------- Gordon Banks  N3JXP      | \"Skepticism is the chastity of the intellect, and geb@cadre.dsl.pitt.edu   |  it is shameful to surrender it too soon.\"  ----------------------------------------------------------------------------\\n', 'Lots of misc and radio related items for sale! Still trying to lighten my load for moving! Motorola VHF pager, digital, no voice or readout $15 2 Capacitor checkers HP 200CD audio oscillator 5 hz to 600 Khz.   1200 feet + brand new 1/2\" hardline for tv     with new connectors, this is in 5 pieces                                               lots of Gain mobile antennas for VHF and UHF   UHF *amp*, input on 75 Mhz in milliwatts and      output on 450 Mhz, 30 watts out. with service     manual, this came out of a Motorola mobilephone.     make reasonable offer. looking for $40 + shipping     or trade for?   RCA tac 300 UHF dash mount 2channel w/service      manual, great condition,  currently on GMRS     frequency 462.725 repeater and simplex with     PL of 151.4 hz     $100   Nobratron QR 75-2 power supply by Sorensen, w/service     manual, this is a 2 amp variable power supply, I      have used it at 80 vdc. weight is 45lbs  $45.   Motorola tone remote model #1926A, works great,     with monitor button, $75   This unit is used      to remote a base station with only two wires.   Also have tone remote board from Mitrek Super      consolette, make offer, could be used with      above remote! model #TRN-6744A w/schmetics     Both for $100.   Motorola Handhelds, MH-10 (4) w/charger, speaker mic, leather case, currently on 34.830, w/dpl   DPL decks from Motorola moxy radios     very reasonable esp. if you take all, anyone     offer $10 each for all or trade for?    PL reeds, I have some (30 or so I think)    also dpl code plugs    e-mail if you need some or I will sell all cheep.   Transmit tubes for GE radios, new in box.   5 DB gain UHF mobile antennas by motorola,      used, sold new for $90, make reasonable offer.     sell 3 for $45 + shipping   Motorcycle control head and cable with frequency     selector and speaker all in one, 4 channel, I      believe this came from a Micom.     Asking $20 + shipping   channel elements for motorola micor, mitrek, motrac     3 sets of vhf micor,      uhf micor, low band motrac, more   Mobile microphones for GE, Motorola, and RCA      reasonable offer.   Motorola DC remote adaptor model #TLN-1127apr      $75   I still have a few business band service manuals      esp. GE and Motorola, e-mail for details.   Phone restrict toll boxes (2) use quarters  DTMF mobile mic  GE Master Pro UHF mobile, not working, with accessories, this is a trunk mount radio.  $20 + shipping   6\\' GE base cabinet w/19\" rack   Duplexer cabinet from vhf duplexers   19\" rack base cabinet, Johnson   HD satellite dish jack or arm   2 Spools multi-conductor wire, w/shield, thickness is approx 1/2\"   GE Master pro mobile control heads and cables   Eagle model #2 level sensor, tells how full a container is    The above prices do not include shipping! Some of the above items are pickup only because of size or weight, locations is Eastern Ohio.  if interested e-mail me or you can call Jim Sims sr. N4JDP  (614) 439-2177 before 9 PM Eastern re_sims@vax.cns.muskingum.edu                                         \\n', \"In article <20APR199312512640@venus.lerc.nasa.gov> smorris@venus.lerc.nasa.gov (Ron Morris ) writes: >Gerald, Murray wasn't responsible for Primeau (although I'm not >ready to admit that's a horrible pick).  They hired him after the >draft (which has never made sense to me).  His first pick was >Lapointe. I don't think Primeau is necessarily a bad pick...I'm was just trying to locate the beginning of Murray's decisions...he slowness in trading Carson has delayed Primeau's development...and you have to wait longer for big players often...and Primeau can be a very good player without being a point-a-game-player, especially on a team that has Yzerman and Fedorov...if Primeau becomes Joel Otto, and gets 20 goals a season, and plays mean...it will have been an extremely good pick. Gerald\\n\", 'In article <5036@cvbnetPrime.COM> tjohnson@tazmanian.prime.com (Tod Johnson (617) 275-1800 x2317) writes: >In article <18843.1076.uupcb@freddy.ersys.edmonton.ab.ca> grant.barkwell@freddy.ersys.edmonton.ab.ca (Grant Barkwell) writes: >> >>CP>Too my certain knowledge, simply posessing a motorcycle >>CP>can get you \"laid\". >> >>True! Oh so very thankfully true! >Gentlemen; >\\tPlease do us all a rather appropriate favor and excuse the >comments about your sexual fortunes on the net. It is hardly an Tod, I think you\\'ve misspoke.  If they\\'re banking on owning a motorcycle to get them laid, then I doubt they have sexual fortunes.  Quite the reverse... --  Jonathan E. Quist        jeq@lachman.com       Lachman Technology, Incorporated DoD #094, KotPP, KotCF \\'71 CL450-K4 \"Gleep\"                 Naperville, IL  __       There\\'s nothing quite like the pitter-patter of little feet,  \\\\/                   followed by the words \"Daddy!  Yay!\"\\n', 'From the article \"What\\'s New\" Apr-16-93 in sci.physics.research: ........ WHAT\\'S NEW (in my opinion), Friday, 16 April 1993  Washington, DC 1. SPACE BILLBOARDS! IS THIS ONE THE \"SPINOFFS\" WE WERE PROMISED? In 1950, science fiction writer Robert Heinlein published \"The Man Who Sold the Moon,\" which involved a dispute over the sale of rights to the Moon for use as billboard. NASA has taken the firsteps toward this  hideous vision of the future.  Observers were startled this spring when a NASA launch vehicle arrived at the pad with \"SCHWARZENEGGER\" painted in huge block letters on the side of the booster rockets.  Space Marketing Inc. had arranged for the ad to promote Arnold\\'s latest movie. Now, Space Marketing is working with University of Colorado and Livermore engineers on a plan to place a mile-long inflatable billboard in low-earth orbit.  NASA would provide contractual launch services. However, since NASA bases its charge on seriously flawed cost estimates (WN 26 Mar 93) the taxpayers would bear most of the expense. This may look like environmental vandalism, but Mike Lawson, CEO of Space Marketing, told us yesterday that the real purpose of the project is to help the environment! The platform will carry ozone monitors he explained--advertising is just to help defray costs. .......... What do you think of this revolting and hideous attempt to vandalize the night sky? It is not even April 1 anymore. What about light pollution in observations? (I read somewhere else that it might even be visible during the day, leave alone at night). Is NASA really supporting this junk? Are protesting groups being organized in the States? Really, really depressed.              Enzo --  Vincenzo Liguori                             | enzo@research.canon.oz.au Canon Information Systems Research Australia | Phone +61 2 805 2983 PO Box 313 NORTH RYDE NSW 2113               | Fax   +61 2 805 2929\\n', 'sleeping_dragon (ong_mang@iastate.edu) wrote: : I\\'m looking to buy a 17\" monitor soon, and it seems that I can\\'t decide what : monitor I should buy. I have a MAG 17S (this is a .25 dpi version and it using : a TRINITON tube) and a NANAO 560i in mind. Good luck finding an MX17S.  When I was looking around back in December/January, Mag wasn\\'t producing any because they couldn\\'t get tubes from Sony.  I asked when they expected to restart production as I was willing to wait a few months to get an MX17S but they said not any time soon.  I wound up getting a T560i and am extremely happy with it. David --  David Engel                        Optical Data Systems, Inc. david@ods.com                      1101 E. Arapaho Road (214) 234-6400                     Richardson, TX  75081\\n', 'In article <1qu43p$aam@fnnews.fnal.gov>, Greg Schuweiler <schuweiler@fnal.gov> writes: >  > Would like to purchase a trombone for a 9 year old because >  >  \"This really really want I want to play daddy I\\'ll practice everyday and > I\\'ll even keep my room really clean.\"   >  > Well he must really mean it.  Would like to find a used one.  Please > e-mail me at  >  > schuweiler@fnal.gov >  >  > Greg Schuweiler  schuweiler@fnal.gov   I\\'ve got a used one for sale.  I used it in high school and just don\\'t have  the occasion to get it out and play it anymore.  Email me and we can work out  something on it.  I can\\'t get email to you for some reason.  David--  --------------------------------------------------------------------- David B. Snyder                     Logicon Technical Services Inc. dsnyder@falcon.aamrl.wpafb.af.mil   Wright-Patterson Air Force Base 513-255-5165                        Dayton, Ohio USA --------------------------------------------------------------------- It is said that GOD doesn\\'t subtract from ones\\' time on earth, those hours spent flying. --------------------------------------------------------------------- 1946 Cessna 140 N76234 \"The lady in waiting\" Owner/Operator --------------------------------------------------------------------- Opinions expressed are my own and not those of Logicon or the USAF. ---------------------------------------------------------------------\\n', \"In article <C5JLDC.HL9@news.cso.uiuc.edu>, jroberts@ux4.cso.uiuc.edu (Robertson) writes... >Does anybody know the FTP site with the latest Windows drivers for the ATI >GUP? >Thanks >  The latest driver release is 59 and can be found at ftp.cica.indiana.edu in the pub/pc/win3/... directory structure as pro59.zip.  I checked with ATI's BBS last nite and there were no releases past 59. We have the ATI Local Bus card and I noticed that I get garbage around the edges of a window when I move it.  Has anybody else noticed this also? Tom. ------------------------------------------------------------------------------- Thomas B. Fisk          +----------------------------+  Internet: fisk@mayo.edu Mayo Clinic             |   If you don't know where  |  Voice: (507) 255-4341 200 First Street SW     |  you're going you'll never |  FAX: (507) 255-5484 Mail Stop 2D-337 STM    |         get there.         | Rochester, MN  55905    +----------------------------+ -------------------------------------------------------------------------------\\n\", '1. IBM PS/2 286; 30 meg hd; 1.44 disk drive 3.5\"; extended keyboard; mouse,    mouse-pad; DOS, DOSSHELL, EXCEL, WINDO S, WORD, AMIPRO, GRE StudyWare.    $500 / b.o. 2.  Zenith Date Systems supersport laptop computer     w/ 120V AC recharger; model 150-308 60 hz.     DOS 4.0     2 disc drives for 3.5\" floppy     carrying case, manuals.     $350 / b.o. 3.  2 leather desk chairs  (1) black $200. (2) brown $150. or both for $300. 4.  Olivetti manual typewriter, Tropical model.     Incl. characters for typing in Italian language.     $100. Please reply via email or call me at my home number:  (617) 277-9234. Thanks, Jason *---------------------------------------------------------------------* | Jason Boro ....................... jboro@enterprise.bih.harvard.edu | | Center for Clinical Computing .......... Boston, MA  (617) 732-5925 | *---------------------------------------------------------------------*\\n', \"Hi, everyone; I need an advice on what is the best way to get a scumster. Several weeks ago I posted an article on behalf of a friend who wanted an external HD for mac. The scumster - R.E.P. - called my friend and they agreed on a price. My friend (unexperienced and not too fluent in English) paid by check, requesting R.E.P. to call him back when the check arrives and the HD is send. Well, the check was cashed 3/24 and that is that. Phone # that R.E.P. gave is on the answering machine all the time and there is no reaction when the message is left; e-mail address does not bounce but again there is no answer. I know, that R.E.P. is a student at University of Delaware; I have his e-mail address, his US postal address and his (?) phone#. The question is: WHAT IS THE BEST WAY TO PROCEED? Thanks in advance for any advice. Sincerely, Victor Levenson (VVL2H@virginia.edu) P.S. The reason I did not put R.E.P.'s full name is that I still hope... P.P.S. If I get enough responses I will post a summary, maybe even on a regular basis. VL -- ==================================== Dr.Victor V.Levenson               Tel (804) 924 2370 lab Dept. of Biochemistry              Internet VVL2H@virginia.edu\\n\", 'In article <1qrsr6$d59@access.digex.net> kfl@access.digex.com (Keith F. Lynch) writes: >In article <lso15qINNkpr@news.bbn.com> sher@bbn.com (Lawrence D. Sher) writes: >> From the N.E.J.Med.  editorial:  \"The dicarboxylic amino acid glutamate >> is not only an essential amino acid ... >Glutamate is not an essential amino acid.  People can survive quite well >without ever eating any. There is no contradiction here. It is essential in the sense that your body needs it. It is non-essential in the sense that your body can produce enough of it without supplement. Jason Chen\\n', '               Attention Israel Line Recipients                     Friday, April 16, 1993 Two Arabs Killed and Eight IDF Soldiers Wounded in West Bank Car Bomb Explosion Israel Defense Forces Radio, GALEI ZAHAL, reports today that a car bomb explosion in the West Bank today killed two Palestinians and wounded eight IDF soldiers. The blast is believed to be the work of a suicide bomber. Radio reports said a car packed with butane gas exploded between two parked buses, one belonging to the IDF and the other civilian. Both busses went up in flames. The blast killed an Arab man who worked at a nearby snack bar in the Mehola settlement. An Israel Radio report stated that the other man who was killed may have been the one who set off the bomb. According to officials at the Haemek Hospital in Afula, the eight IDF soldiers injured in the blast suffered light to moderate injuries. -Danny Keren\\n', \"In Article <1993Apr16.075822.22121@galileo.cc.rochester.edu>, hlsw_ltd@uhura.cc.rochester.edu (Dave Hollinsworth) wrote: >With a little luck, I could own a C650 sometime in the near future, and >so I was just wondering if someone could clear these two questions up for me: >1.  What speed SIMMS does the C650 need/want?  (I know that it needs 80ns >VRAM...not sure for the main RAM.) 60ns 72 pin simms. >2.  I've heard two conflicting stories about the total expandibility of the >C650's RAM...132 and 136 megs.  Which is true?  (Perhaps another phrasing >would be better:  does the 8 meg version come with all 8 megs on the logic >board, or 4 megs + a 4 meg SIMM?) 2 configs: 4mb & 8mb. In each case the memory is soldered on the board leaving the 4 simm sockets open. 132mb is the total addressable memory for a 650. >Just wondering.... Michael A. McGuire, :-) MCGUIRE@UTKVX.UTK.EDU UTCC - User Services\\n\", 'Here is another way of looking at it. When we die we are released from the arc of time, and able to comprehend our lives in toto.  To visit each moment in time sequentially or all at once, but not able to alter the actions thoughts or feelings we had/have/will have in this  life. From that perspective, I posit that all will have direct knowledge of God, and be able to recognize at each moment of time wether we were doing what we ought.  That the experience of having lived a life far from God will be an eternal torment.  That  having lived a life of grace, will be an eternal joy.  That the  resurrection of the body comes not from any physical reconstitution of our present forms, but knowledge of our present forms by our fully cognizant souls. As an Aside:  If we were to be restricted for all time to our present form, would you opt for immortality? James Sledd think in n dimensions & listen for the voice of God\\n', 'Curtis Mathes VHS VCR Remote included and it works with universal remotes.  2 heads, Works great but I replaced it with a Stereo VCR.  paid $300 years ago, will sell for $125 delivered OBO. Radio Shack stereo amp.  2 inputs, tone, and left and right volume.  Speakers  not included.  Compact 12W unit for $20 plus shipping.  Great for Amiga  Stereo output or Soundblaster output. If you are interested in either of the above mail me, Keith, at radley@gibbs.oit.unc.edu or call me at 919-968-7779. I did have these sold but both deals fell thru so if you are still interested in either email or call me.         _     _  //       Major: Computer Science              /<eith Radley     \\\\\\\\//        Minor:     English              Radley@gibbs.oit.unc.edu      \\\\/      Computer:   AMIGA 3000           University of North Carolina\\n', \"Does anyone know where I can still get an internal fax modem for the  original mac portable? I know they were made for a while by several  manufacturers, but I can't find them now. thanks for your help. Gene Wright --      gene@jackatak.raider.net (Gene Wright) ------------jackatak.raider.net   (615) 377-5980 ------------\\n\", 'dbd@urartu.sdpa.org (David Davidian) writes: >On the 78th Commemorative Anniversary of the Turkish genocide of the Armenians, >we remember those whose only crime was to be Armenian in the shadow of an  >emerging Turkish proto-fascist state. In their names we demand justice. >In April 1915, the Turkish government began a systematically executed  >de-population of the eastern Anatolian homeland of the Armenians through a  >genocidal extermination. This genocide was to insure that Turks exclusively >ruled over the geographic area today called the Republic of Turkey. The  >result: 1.5 million murdered, 30 billion dollars of Armenian property stolen >and plundered. This genocide ended nearly 3,000 years of Armenian civilization >on those lands. Today, the Turkish government continues to scrape clean any >vestige of a prior Armenian existence on those lands. Today\\'s Turkish >governmental policy is to re-write the history of the era, to manufacture >distortion and generate excuses for their genocide of the Armenian people. In  >the face of refutation ad nauseam, the Turkish Historical Society and cronies  >shamelessly continue to deny that any such genocide occurred. This policy  >merely demonstrates that in the modern era, genocide is an effective state  >policy when it remains un-redressed and un-punished. A crime unpunished is a  >crime encouraged. Adolf Hitler took this cue less than 25 years after the  >successful genocide of the Armenians. [ ... ] >ARMENIANS DEMAND JUSTICE                              ERMENILER ADALET ISTIYOR >--  >David Davidian dbd@urartu.sdpa.org   | \"Armenia has not learned a lesson in >S.D.P.A. Center for Regional Studies |  Anatolia and has forgotten the  >P.O. Box 382761                      |  punishment inflicted on it.\"  4/14/93 >Cambridge, MA 02238                  |   -- Late Turkish President Turgut Ozal  To which I say: Hear, hear.  Motion seconded. Hovig --  Hovig Heghinian University of Illinois at Urbana-Champaign Department of Computer Science\\n', 'Hi there, I\\'ve made a VGA mode 13h graphics library available via FTP.  I originally wrote the routines as a kind of exercise for myself, but perhaps someone here will find them useful.  They are certainly useable as they are, but are missing some higher-level functionality.  They\\'re intended more as an intro to mode 13h programming, a starting point. *** The library assumes a 386 processor, but it is trivial to modify it *** for a 286.  If enough people ask, I\\'ll make the mods and re-post it as a *** different version. The routines are written in assembly (TASM) and are callable from C.  They are fairly simple, but I\\'ve found them to be very fast (for my purposes, anyway).  Routines are included to enter and exit mode 13h, define a \"virtual screen\", put and get pixels, put a pixmap (rectangular image with no transparent spots), put a sprite (image with see-thru areas), copy areas of the virtual screen into video memory, etc.  I\\'ve also included a simple C routine to draw a line, as well as a C routine to load a 256 color GIF image into a buffer.  I also wrote a quick\\'n\\'dirty(tm) demo program that bounces a bunch of sprites around behind three \"windows\". The whole package is available on spang.camosun.bc.ca in /pub/dos/vgl.zip  It is zipped with pkzip 2.04g It is completely in the public domain, as far as I\\'m concerned.  Do with it whatever you like.  However, it\\'d be nice to get credit where it\\'s due, and maybe an e-mail telling me you like it (if you don\\'t like it don\\'t bother) Mark morley@camosun.bc.ca\\n', 'I want to convert a 500 Volt sinewave with frequency between 1 kHz and 10 kHz, to a 10 Volt sinewave with the same frequency, by means of a transformer. The secondary current will be .6 A (600 mA). What kind of transformer should I use (ferrite?) Can I buy one? If so, I need a partnumber and supplier If I cannot buy one, how do I go about winding one myself? What core do I use, how big must it be in order not to saturate, what thickness copper wire, how many turns, etc.? I know little about analog electronics, so I hope some kind soul here will help me out. Pointers to relevant databooks will also be highly appreciated. Thanks, Mark de Rooi rooi@tpd.tno.nl\\n', 'Where do I find the Athena Widgets that are needed for xtdm-2.4.8  Thanks in advance\\n', \"Has someone a list of CD-ROM's with no SCSI-Interface and if known how much they are present in the market. Please mail direcktly as I am not reguarly reading the group. I'll post a summary if wanted. Thanks Ihno ============================================================================== Ihno Krumreich       | Phone (49) 721 955 253 0        U   U N   N  III  X   X Synerix Gmbh         | email: ihno@generics.ka.sub.org U   U NN  N   I    X X Bach Strasse 24      | FAX   (49) 721 59 02 11         U   U N N N   I     X D-W7500 Karlsruhe 21 |                                 U   U N  NN   I    X X                                                         UUU  N   N  III  X   X --  ============================================================================== Ihno Krumreich       | Phone (49) 721 955 253 0        U   U N   N  III  X   X Synerix Gmbh         | email: ihno@generics.ka.sub.org U   U NN  N   I    X X\\n\", \"In article <C5L5x0.KJ7@vcd.hp.com> johne@vcd.hp.com (John Eaton) writes: >-s87271077-s.walker-man-50- (swalker@uts.EDU.AU) wrote: >During the nuclear fission reaction the uranium fuel can get hot enough >to melt. When this happens the liquid uranium is pumped to the cooling >tower where it is sprayed into the air.  \\tNonsense.  First, the uranium fuel is sealed in zirconium alloy cylinders (which don't melt in any circumstances short of  major failure of the power plant).  Second, the primary water (that circulates inside the reactor core) is never pumped into the cooling tower (it's the SECONDARY water cycle that goes  through the cooling tower).  Third, liquid uranium would burst into flame on contact with air. >Contact with the cool outside air >will condense the mist and it will fall back to the cooling tower floor. >There it is collected by a cleaning crew using shop vacs and is then >reformed into pellets for reactor use the next day. \\tCleaning crew working in a mist of uranium?  This is a toxic heavy metal, even if it WEREN'T radioactive.  Shouldn't there be some smileys here?  Or frowneys?  \\tJohn Whitmore\\n\", \"In article <C5Joz9.HLn@cup.hp.com> Chris Steinbroner <hesh@cup.hp.com> writes: >Wm. L. Ranck (ranck@joesbar.cc.vt.edu) wrote: >: As a new BMW owner I was thinking about signing up for the MOA, but >: right now it is beginning to look suspiciously like throwing money >: down a rathole. >[...] i'm going to >let my current membership lapse when it's >up for renewal. >-- hesh In my case that's not for another 3+ years, so I'd appreciate any hints on what will keep the organization in business that long.  (And preferably longer, of course, and worth being part of.) -- David Karr (karr@cs.cornell.edu)\\n\", \"*Reminder*   Plan now for the Andrew Conference. *Date* The dates are as noted below.  (We have not changed them.) *Submission extension*   We are still accepting papers. *Tutorial topic*   \\t_Converting Andrew source code to C++_ This tutorial will discuss the steps necessary to convert a site from C (extended with classC) to C++.  Conversion of the source code requires only a couple of steps: \\trun the converter \\tfill in missing type information Describing this will not take long.  The remainder of the day will be spent learning how to write objects in C++ and practicing. ------------------------------ 1993 Andrew Technical Conference and Consortium Annual Meeting June 24-25, 1993 Carnegie Mellon University Pittsburgh, PA The conference will be held on the last Thursday and Friday in June.  A tutorial will be on Thursday the 24th and the conference proper on the 25th with the annual meeting at the dinner on the evening between the two days.  All conference attendees are welcome at the annual meeting, though only Consortium members will be able to vote. This year's theme is  \\tApplication Construction by Non-Programmers Much of the effort on X toolkits has been aimed at programmer construction of applications.  There have, however, been some excellent UIMS systems built on top of X.  Papers addressing the theme will consider questions such as \\tWhat is needed for application construction by non-programmers? \\tCan we avoid programming altogether, or is a simple language needed? \\tIs it sufficient to create applications, or must users be able to create new widgets? \\tShould widgets and applications be able to print themselves? Your participation in the conference is welcome.  Papers are appropriate on the theme or any aspect of the Andrew User Interface System, including \\tapplications \\texperience with users \\tnew objects \\treviews of and proposals for revision of  \\t\\tinternal Andrew protocols We expect to have an RS/6000 with video projector available if you would like to do a demonstration.   Paper proposals should be submitted by 15 May 1993. Acceptance will be 1 June with final papers due by 15 June. Send papers via electronic mail to wjh+@andrew.cmu.edu. Fred Hansen Director, Andrew Consortium\\n\", \"In article <michael.735318247@vislab.me.iastate.edu> michael@iastate.edu (Michael M. Huang) writes: >MSG is common in many food we eat, including Chinese (though some oriental >restaurants might put a tad too much in them).  I've noticed that when I >go out and eat in most of the Chinese food restaurants, I will usually get >a slight headache and an ununsual thirst afterwards.  This happens to many >of my friends and relatives too.  And, heh, we eat Chinese food all the >time at home :) (but we don't use MSG when we're cooking for ourselves) >So, when we put one and one together, it can be safely assumed that >MSG may cause some allergic reactions in some people. >Stick with natural things.  MSG doesn't do body any good (and possibly >harms, for that matter).  So, why bother with it?  Taste food as it should >be tasted, and don't cloud the flavor with an imaginary cloak of MSG. As I understood it, MSG *is* natural.  Isn't it found in  tomatoes? Anyway, lots of people are terribly allergic to lots of natural things; peanuts, onions, tomatoes, milk, etc.  Just because something is 'natural' doesn't mean it won't cause problems with some folks. As for how foods taste:  If I'm not allergic to MSG and I like the taste of it, why shouldn't I use it?  Saying I shouldn't use it is like saying I shouldn't eat spicy food because my neighbor has an ulcer. People have long modified the taste of food by additives, whether they be chiles, black pepper, salt, cream sauces, etc.  All of these things cloud the flavor of the food.  Why do we bother with them? How should food be tasted?  Isn't it better left to the diner? Julie\\n\", 'last night bill veeck cam to me in my dreams and this is what he said: cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs scuk cubs suck cubs suck cubs suck cubs cuck cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck oh yeah, he aqlso added that harry is a drunken idiot who shoulda stayed in st louis where his heart is, but also added that fair weathered fans all like to be together.  i guess this is the reason harry is now a cub fan, bud man.  note he never really left st, louis. jim walker go sox, cubs suck!\\n', 'I have found Jewish people very imagentative and creative. Jewish religion was the foundation for Christianity and Islam.  In other words Judaism has fathered both religions. Now Islam has turned against its father I may say. It is Ironic that after communizem threat is almost gone, religion wars are going to be on the raise.  I thought the idea of believing on one God, was to Unite all man kind. How come both Jews and Islam which believe on the same God, \"the God of Ebrahim\" are killing each other? Is this like Dr. Frankenstien\\'s story? How are you going to stop this from happening? How are you going to deal with so many Muslims. Nuking them  would distroy the whole world? Would God get mad, since you have killed his followers, you believe on the same God, same heaven and the same hell after all? What is the peacefull way of ending this Saga? Man kind needs religion, since it sets up the rules and the regulations which keeps the society in a healthy state. A religion is mostly a sets of rules which people have experienced and know it works for the society. The praying, keeps the sole healthy and meditates it. God does not care for man kinds pray, but man kind hopes that God will help him when he prays. Religion works mostly on the moral issues and trys to put away the materialistic things in the life. But the  religious leaders need to make a living through religion? So they  may corrupt it, or turn it to their own way to make their living. i.e Muslims have to pay  %20 percent of their income to the Mullahs. I guess the rabie  gets his cut too!  Is in it that religion should be such that everybody on planet earth respects each other, be good toward each other helps one another, respect the mother nature. Is in that heaven and hell are created on earth through the acts  that we take today?  Is in it that within every man there is good and bad, he could choose either one, then he will see the outcome of his choice.  How can we prevent man kind from going crazy over religion. How can we stop another religious killing field, under poor Gods name? What are your thoughts? Do you think man kind would to come its senses, before it is too late? P.S. on the side Do you think that Moses saw the God on mount Sina? Why would God go to top of the mountain? He created the earth, he could have been anywhere? why on top the mountain? Was it because people thought to see God you have to reach to the skies/heavens? Why God kept coming back to Middle East? Was it because they created God through their imagination?  Is that why Jewish people were told by God, they were the chosen ones? Profit Mohammad was married to Khadijeh. She was a Jewish. She taught him how to trade. She probably taught him about Judaism. Quran is mostly copy right of Taurah (sp? old testement). Do you think God wrote Quran? Makeh was a trade city before Islam. Do you think it was made to be the center of Islamic world because Mohammad wanted to expand his trade business? Is that why  God has put his house in there?  I think this religious stuff has gone too far. All man kind are going to hurt from it if they do not wise up. Look at David Koresh, how that turned out? I am afraid in the bigger scale, the Jews and the Muslims will have the same ending!!!!!!!! Religion is needed in the sense to keep people in harmony and keep them doing good things, rather than plotting each others distruction.  There is one earth, One life and one God. Let\\'s all man kind be good toward each other. God help us all. Peace\\n', 'In article <1r27ld$bp2@transfer.stratus.com> cdt@sw.stratus.com (C. D. Tavares) writes: >In article <C5t38G.IL@news.udel.edu>, roby@chopin.udel.edu (Scott W Roby) writes: >> In article <1r1rad$7rl@transfer.stratus.com> cdt@sw.stratus.com (C. D. Tavares) writes: >> >In article <C5s0Ds.J54@news.udel.edu>, roby@chopin.udel.edu (Scott W Roby) writes: >>  >>   [The original question was about who started the fire and whether the  >>    \"madmen\" were inside or outside the compound.  To which I replied on  >>    the possible sanity level of those inside and outside.] >Was THAT your argument.  Well, you didn\\'t make it very well.  You started  >from the questionable premise that the fire was necessarily an act of >insanity, rather than an act of negligence or an accident.  Recall, one >survivor claims that the fire started when a tank knocked over a kerosene  >lamp.  Kind of makes arguments regarding relative sanity somewhat moot, no? And another survivor claims he heard someone shouting \"The fire\\'s started!\". Odd terminology.  That\\'s what one says when you know a fire is planned, not  when one occurs by accident.  We will have to wait and see what the evidence  shows, assuming one is willing to believe any evidence offered by the  \"distrustful ones\". >> >> According to an Australian documentary made in the year before the stand off  >> >> began, Koresh and his followers all believed he was Christ.  Koresh  >> >> had sex with children and women married to other men in the compound.   >> >> These were the \"perfect children\" resulting from the \"great seed\" of  >> >> his \"magnified horn\".  Ex-members describe him in ways not dissimilar  >> >> to the way Jim Jones has been described. >> > >> >Point noted.  Have you submitted YOUR faith and sex life for BATF clearance? >> >Better hurry; I believe the deadline was April 15. >>  >> I paid my taxes.  There was no reference to sex or religion on the form. >> The comments above and below were meant to address who might be unstable  >> enough to keep children in a building with tear gas or start a fire. >\"Nice evasive maneuver, Mr. Chekov, but they\\'re still on our tail.\" >Let me ask it more plainly.  Which of the above complaints about David  >Koresh\\'s religious or sexual proclivities justified an armed raid by the  >Bureau of Alcohol, Tobacco, and Firearms? Neither.  Again I was merely addressing the sanity level of the players.   I agree that the BATF handled the affair badly from day one.  BTW, I heard  on the news today that the affadavit behind the no-knock warrant was unsealed  today.  Grenade launcher was the only thing on the list that I found  unusual. >> >> >:Two of the nine who escaped the compound said the fire was deliberately set  >> >> >:by cult members. >> >> So, when they talk to the news reporters directly, and relate the same details,  >> >> will you believe them? >> >Believe them?  I won\\'t even RECOGNIZE them.  And neither will anyone else >> >who doesn\\'t know them personally. >> Do you believe they would put impostors before the national tv cameras? >It\\'s not entirely far-fetched.  Nobody outside the compound would know  >EVERYBODY inside the compound.  Don\\'t forget, the BATF admits having  >agents inside the compound, in any case. Ambitious news reporters could use the documentary filmed by an Australian  in 1992 on the compound grounds to help identify survivors.  I, for one,  will check their stories for consistency with what I learned in a long  news story about that documentary. >> At this point, we are getting conflicting reports from the survivors. >> Best wait til more light is shed upon them.  Of course, this is no  >> good if you believe in eternal darkness. >I\\'m simply being the devil\\'s advocate.  There\\'s reasonable doubt by the >boatload standing in the way of anybody totally swallowing the official  >government story on Waco. Certainly there is some room for doubt.  I certainly reserve the right  to change my opinions when new evidence warrants such a change.  If I  were conspiratorially minded, however, I would never be able to change  my mind, because any evidence I disliked would have to be a lie  fabricated by the \"distrustful ones\". -- \\n', '              Any opinions expressed are strictly those of the               user and not necessarily those of Ericsson. In article <1993Apr21.131908.29582@uhura.neoucom.edu> wtm@uhura.neoucom.edu (Bill Mayhew) writes: >From: wtm@uhura.neoucom.edu (Bill Mayhew) >Date: Wed, 21 Apr 1993 13:19:08 GMT >Write a good manual to go with the software.  The hassle of >photocopying the manual is offset by simplicity of purchasing >the package for only $15.  Also, consider offering an inexpensive >but attractive perc for registered users.  For instance, a coffee >mug.  You could produce and mail the incentive for a couple of >dollars, so consider pricing the product at $17.95. Or, _documentation_ for the program ;-).  A lot of shareware out there is  very similar in the approach - send in your money, and you get  documentation, and a free upgrade to the latest version.  Perhaps even  support of some small degree.  Whatever you want to offer that is \"better\"  than the circulating version. >You\\'re lucky if only 20% of the instances of your program in use >are non-licensed users. Figure about 50%, as I have seen. >The best approach is to estimate your loss and accomodate that into >your price structure.  Sure it hurts legitimate users, but too bad. It doesn\\'t really hurt legit users.  Shareware is still much cheaper than  the alternatives.  ----------------------------------------------------------------------------  ---------Visit the SOUNDING BOARD BBS +1 214 596 2915, a Wildcat! BBS-------  ObDis: All opinions are specifically disclaimed. No one is responsible.     Patrick Taylor, Ericsson Network Systems  THX-1138     exuptr@exu.ericsson.se                    \"Don\\'t let the .se fool you\"\\n', '  QUESTION:   What is the EXACT entry (parameter and syntax please), in the X-Terminal configuration file (loaded when the X-Terminal boots), to add another system  to the TCP/IP access control list?      BACKGROUND:   I have two unix systems, 1. an AT&T 3B2 running X11R3 and MIT\\'s X11R4 and  2. a Sun SS10 without any X.     I want to have a window to the Sun and the 3B2 on the NCD X-Terminal at the same time.  I can do this if I manually set the Network Parameter TCP/IP Access Control List to off, then login to my telnet session. Not Great!     I\\'ve tried to get \"xhost\" to work and failed.  Either my syntax is wrong or the X11R3 implementation is bogus.     I am trying to edit the NCD configuration file that is loaded when the  NCD boots.  No matter what entry I add or edit, the NCD still boots with the TCP/IP Access Control list containing only the 3B2.   My manuals are worthless so any help would be most appreciated!!  Thanks! Ann Marie Barden  \\tabarden@afseo.eglin.af.mil\\n', \"In <1993Apr15.170715.29896@igor.tamri.com> donb@igor.tamri.com (Don Baldwin) writes: |>Think about it -- shouldn't all drugs then be legalized, it would lower |>the cost and definitely make them safer to use. |I think so.  And I don't use drugs, outside of the legal ones (alcohol |and coffee). I'm addicted to chocolate myself. --  Mob rule isn't any prettier merely because the mob calls itself a government It ain't charity if you are using someone else's money. Wilson's theory of relativity: If you go back far enough, we're all related. Mark.Wilson@AtlantaGA.NCR.com\\n\", 'In article <cmay.734085409@helium>, cmay@helium.gas.uug.arizona.edu (Christopher C May) writes: |> In <1993Apr2.232511.10711@raid.dell.com> mikepb@lupus.dell.com (Michael P. Brininstool) writes: |>  |> >Swatikas were also common in American Indian markings/painted walls etc.  Is |> >it the Swastika that is bad?   |>  |> Just want to back this up with a personal anecdote.  My grandparents |> have a Navajo rug made in the 1920\\'s, which they received in trade  |> from the weaver while living in Flagstaff, Arizona.  The decorative motif |> consists of 4 large black swastikas, one in each corner.  What\\'s more, the |> color scheme is black, white, and red.  To the casual glance it would |> undoubtedly appear to be a Nazi relic of some kind.  Yet they owned it |> ten years before Hitler and the National Socialists came to power.   |>  |> As I recall, they took it down in the 30\\'s, and didn\\'t feel quite right |> about putting it back up until the 60\\'s.  It still draws comments from  |> those who don\\'t know what it is. Having lived, played, and worked on and near the Navajo reservation for a number of years, I can confirm this is an ancient pattern, found in petroglyphs dated 800 to 1200 years old. Also, the Indians never stopped making rugs with this pattern - they just stopped selling them after the Nazi\\'s pre-empted the swastika. Note also that the Indian versions use both clockwise and counter-clockwise swastikas. Ob guns:  It\\'s the rare Navaho family that doesn\\'t own a rifle.  They remember being \"relocated\" by the US Army, and don\\'t intend to do it again.  The Hopi, on the other hand, have a dislike for weapons, from my experience.  Perhaps they just hide them better from strangers. --  Kirk Hays - NRA Life, seventh generation. \"The only thing necessary for the triumph of evil is for good men to do nothing.\"  -- Edmund Burke (1729-1797)\\n', 'In article ( ), wsmart@tay.mcs.dundee.ac.uk (Bill Smart) writes: > To get the number back, the other client does: >  AppAtom = XInternAtom(display,\"ApplicationWindow\",True); >  XGetWindowProperty(display,DefaultRootWindow(display),AppAtom,0,8192, >                     False,XA_WINDOW,&return_type,&return_format, >                     &nitems_return,&bar,&return_place); > and appears to get back something valid (just not the right number). > It always seems to return the same number, regardless of the window > number stored in the property. \"return_place\" is probably incorrect.  It should be a pointer, not an integer.  XGetWindowProperty() allocates memory, copies the data there, and returns a pointer to the memory.  You should free the memory when you\\'re done. --- Ken Lee, klee@synoptics.com\\n', \"In article <1qi8e3$b5e@lll-winken.llnl.gov>, you say: >I would like to digitize the output of a SQUID magnetometer (range -10 V >to +10 V) and do digital signal processing in a computer, say a Macintosh >II or a 486 PC.  I would like a good 16 bit ADC with good linearity and a >high conversion speed, at least 50 kHz, preferably 200 kHz.  Other concerns >(2)  Must I use an ADC external to my computer to avoid digital noise >     feedback into my sensitive SQUID electronics? Might be a good idea...  The resolution you requested is about 0.3mV In order to get what you've paid for, noise level better be lower than that.  It is kind of hard to do it in a noisy box like you can expect inside a PC. Before you pay $$$ for a PC card, test it out by sampling a low distortion sine wave (I think there is a sine wave on a CD.  Digital Domain ?  There are possibly other low THD sources)  Run the digitized waveform through a FFT transform and take alook at the noise floor on the spectrum.  That's should give you a good indication of the design. (That's what I am doing to test a data acquistion system I have designed - I got the idea from MAXIM data sheet.) If you can live with 14 bit resolution, I would recommend looking at the MAX121 from MAXIM.  It is a high speed (308KHz) complete sampling A/D with DSP interface.  The input range is +/- 5V and it uses a serial interface (which can easily be optically isolated from the computer to elinimate a major noise source)  The Analog design guide I got from them shows a -100db noise level.  They claim a -77db max (-85 typ.) THD.  Looks pretty good for the $12 @ 1000 pieces A evaluation kit is available.  Might want to give these nice folks a call.  1-800-998-8800 or fax: (408)737-7194 and (408) 737-7600 ext4000 for application assistance. This assumes that you can build your own DAS and write your own software. (Hey you can get the MAX121 as a free sample just by calling the 1-800 #) >I would appreciate discussion of your personal experience with a Mac or PC- >based ADC system. I would recommend you to find out the resolution that can be gotten out of your system by looking at the noise level, otherwise you might be throwing out your money. >Charles Cunningham >cec@imager.llnl.gov K. C. Lee Elec. Eng. Grad. Student I have no connection with MAXIM except I do in general recommend companies that give samples to students to others.  I feel they deserve that for being nice to me.\\n\", \"In article <C5HqJ0.57@unix.amherst.edu> bhtulin@unix.amherst.edu (Barak H. Tulin) writes: >I just started reading this thread today, so forgive me if it has already been >mentioned.  But...what was the deal with Renault's putting the horn on the >left-hand turn-signal stalk?  It was a button on the end, where the washer >button would be on the wiper/washer stalk.  Could the Frenchies not figure >out the wiring through the steering wheel, or what?   Well, before we start calling the Engineering folks in France a bunch of braindeads for this...    My 1979 Mercury Capri had this lovely feature. This was not the earlier German variant but the newer one that was identical to the Mustang of  current fame. I can't tell you how many times this feature pissed me off. Come to think of it my brothers Zepher had this as well. Robert Dilmore dilmore@cray.com >Going back to an earlier thread, imagine having to turn left, shift gears, >flash a stray driver in the intersection with your left-hand high beam on >the headlight stalk, AND, after the driver wouldn't move, having to honk the >horn on the left-hand stalk!  Gives me the heebie-jeebies. >--Barak\\n\"]\n"
          ]
        }
      ],
      "source": [
        "print(generated_output)\n",
        "print(reference_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGzQdiypR3dw",
        "outputId": "97b069e9-a55d-4a82-969b-d2b65fed1586"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "#information from https://www.kaggle.com/code/ralphkrueger/nltk-bleu-score-calculator\n",
        "#Calculate and print BLEU-1, using 1-grams as highest-order n-grams\n",
        "#Reference is placed in [square brackets] because you can score the machine-translated sentence against multiple references.\n",
        "#The weights are set so that calculation is based solely on 1-gram precision.\n",
        "\n",
        "#https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "#reference_text = \"It is a guide to action which ensures that the military always obeys the commands of the party. He read the book because he was interested in world history.\"\n",
        "#candidate_text = \"It is a guide to action that ensures that the military will forever heed Party commands. It is the guiding principle which guarantees the military forces always being under the command of the Party. It is the practical guide for the army always to heed the directions of the  party. He was interested in world history because he read the book.\"\n",
        "#reference_text = sent_tokenize(reference_text)\n",
        "#candidate_text = sent_tokenize(candidate_text)\n",
        "\n",
        "reference_text = reference_output\n",
        "candidate_text = generated_output\n",
        "\n",
        "reference_text = [word_tokenize(t) for t in clean_tokens(reference_text)]\n",
        "candidate_text = [word_tokenize(t) for t in clean_tokens(candidate_text)]\n",
        "if len(reference_text) > len(candidate_text):\n",
        "  reference_text = reference_text[:len(candidate_text)]\n",
        "else:\n",
        "  candidate_text = candidate_text[:len(reference_text)]\n",
        "#print(reference_text)\n",
        "#print(candidate_text)\n",
        "\n",
        "def bleu1(reference_text, candidate_text):\n",
        "  bleu_score = corpus_bleu(reference_text, candidate_text, weights=(1, 0))\n",
        "  metrics[\"BLEU-1\"] = bleu_score\n",
        "\n",
        "def bleu2(reference_text, candidate_text):\n",
        "  bleu_score = corpus_bleu(reference_text, candidate_text, weights=(0.5, 0.5))\n",
        "  metrics[\"BLEU-2\"] = bleu_score\n",
        "\n",
        "def bleu3(reference_text, candidate_text):\n",
        "  bleu_score = corpus_bleu(reference_text, candidate_text, weights=(0.333, 0.333, 0.334))\n",
        "  metrics[\"BLEU-3\"] = bleu_score\n",
        "\n",
        "def bleu4(reference_text, candidate_text):\n",
        "  bleu_score = corpus_bleu(reference_text, candidate_text, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "  metrics[\"BLEU-4\"] = bleu_score\n",
        "\n",
        "print(bleu1(reference_text, candidate_text))\n",
        "print(bleu2(reference_text, candidate_text))\n",
        "print(bleu3(reference_text, candidate_text))\n",
        "print(bleu4(reference_text, candidate_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aM1nKAQWU0yt",
        "outputId": "f5f70f0f-8856-4a4a-d94c-f327663c7c8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It is a guide to action which ensures that the military always obeys the commands of the party. He read the book because he was interested in world history.\n",
            "It is a guide to action that ensures that the military will forever heed Party commands. It is the guiding principle which guarantees the military forces always being under the command of the Party. It is the practical guide for the army always to heed the directions of the  party. He was interested in world history because he read the book.\n",
            "7.57965434483665e-155\n",
            "3.6718992240469637e-78\n",
            "3.844853295436682e-78\n",
            "6.3497053018839554e-232\n",
            "1.8791881298709114e-78\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "#reference_text = \"It is a guide to action which ensures that the military always obeys the commands of the party. He read the book because he was interested in world history.\"\n",
        "#candidate_text = \"It is a guide to action that ensures that the military will forever heed Party commands. It is the guiding principle which guarantees the military forces always being under the command of the Party. It is the practical guide for the army always to heed the directions of the  party. He was interested in world history because he read the book.\"\n",
        "#reference_text = sent_tokenize(reference_text)\n",
        "#candidate_text = sent_tokenize(candidate_text)\n",
        "#reference_text = [word_tokenize(element) for element in reference_text]\n",
        "\n",
        "def self_bleu(reference_text, candidate_text):\n",
        "  self_bleu_scores = []\n",
        "\n",
        "  ### get rid of special characters and split sentences\n",
        "  reference_text = clean_tokens(reference_text)\n",
        "  candidate_text = clean_tokens(candidate_text)\n",
        "#  print(\"REFERENCE:   \", reference_text)\n",
        "\n",
        "  for i in range(len(candidate_text)):\n",
        "    #have all references == candidate text without one sentence we want to use for score\n",
        "    remaining_sentences = candidate_text.copy()\n",
        "    remaining_sentences.pop(i)\n",
        "#    hyp = candidate_text[i]\n",
        "\n",
        "    hyp = word_tokenize(candidate_text[i])\n",
        "    remaining_sentences = [word_tokenize(element) for element in remaining_sentences]\n",
        "\n",
        "    bleu_score = sentence_bleu(remaining_sentences, hyp)\n",
        "    self_bleu_scores.append(bleu_score)\n",
        "#    print(bleu_score)\n",
        "\n",
        "#  for i in candidate_text:\n",
        "#    sentence_copy = copy.deepcopy(candidate_text)\n",
        "#    remaining_sentences = sentence_copy.remove(i)\n",
        "#    sentence_copy = word_tokenize(sentence_copy)\n",
        "#    remaining_sentences = [word_tokenize(element) for element in remaining_sentences]\n",
        "#    bleu_score = sentence_bleu(remaining_sentences, sentence_copy)\n",
        "#    self_bleu_scores.append(bleu_score)\n",
        "#    print(bleu_score)\n",
        "\n",
        "  avg_self_bleu = np.mean(self_bleu_scores)\n",
        "  metrics[\"SELF-BLEU\"] = avg_self_bleu\n",
        "\n",
        "  return avg_self_bleu\n",
        "\n",
        "print(self_bleu(reference_output, generated_output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIUUROA-oxHL",
        "outputId": "a450b65a-ed51-4ed3-e521-5bbf63738d77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ],
      "source": [
        "%pip install rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbLF5_doosrw",
        "outputId": "eb845743-3fc1-4275-c6c5-fa646bccfc16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'rouge-1': {'r': 0.9615384615384616, 'p': 0.625, 'f': 0.7575757528007345}, 'rouge-2': {'r': 0.6428571428571429, 'p': 0.32727272727272727, 'f': 0.43373493528814056}, 'rouge-l': {'r': 0.8076923076923077, 'p': 0.525, 'f': 0.6363636315886134}}]\n"
          ]
        }
      ],
      "source": [
        "# https://pypi.org/project/rouge/?ref=blog.paperspace.com\n",
        "from rouge import Rouge\n",
        "rouge = Rouge()\n",
        "\n",
        "#reference_text = \"It is a guide to action which ensures that the military always obeys the commands of the party. He read the book because he was interested in world history.\"\n",
        "#candidate_text = \"It is a guide to action that ensures that the military will forever heed Party commands. It is the guiding principle which guarantees the military forces always being under the command of the Party. It is the practical guide for the army always to heed the directions of the  party. He was interested in world history because he read the book.\"\n",
        "\n",
        "def calculate_rouge(reference_text, candidate_text):\n",
        "    scores = rouge.get_scores(candidate_text, reference_text)\n",
        "    return scores\n",
        "\n",
        "print(calculate_rouge(reference_output, generated_output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7Fd6AtjUZAb",
        "outputId": "7c1807a3-9c51-48ee-b0d9-a36bd9534608"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "METEOR Score: 0.345925\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.345925"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#METEOR SCORE\n",
        "from nltk.translate import meteor\n",
        "import numpy as np\n",
        "import copy\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "#def calculate_meteor(candidate, reference):\n",
        "def calculate_meteor(reference_text, candidate_text):\n",
        "  reference_text = clean_tokens(reference_text)\n",
        "  candidate_text = clean_tokens(candidate_text)\n",
        "#  reference_text = clean_tokens(sent_tokenize(reference_text))\n",
        "#  candidate_text = clean_tokens(sent_tokenize(candidate_text))\n",
        "#  print(\"REFERENCE:   \", reference_text)\n",
        "\n",
        "  meteor_scores = []\n",
        "  for i in range(len(candidate_text)):\n",
        "    #have all references == candidate text without one sentence we want to use for score\n",
        "    remaining_sentences = candidate_text.copy()\n",
        "    remaining_sentences.pop(i)\n",
        "\n",
        "    hyp = candidate_text[i]\n",
        "#    print(\"SENTENCE: \",hyp)\n",
        "#    print(\"REMAINING: \", remaining_sentences)\n",
        "\n",
        "    hyp = word_tokenize(hyp)\n",
        "    remaining_sentences = [word_tokenize(element) for element in remaining_sentences]\n",
        "\n",
        "    meteor_score = round(meteor(remaining_sentences, hyp), 4)\n",
        "    meteor_scores.append(meteor_score)\n",
        "\n",
        "  avg_meteor = np.mean(meteor_scores)\n",
        "  metrics[\"meteor\"] = avg_meteor\n",
        "  print(f\"METEOR Score: {avg_meteor}\")\n",
        "\n",
        "  return avg_meteor\n",
        "\n",
        "#reference_text1 = \"It3 5 is a guide to action which ensures that the military8 always obeys the commands of the party. He read the book because he was interested in world history.\"\n",
        "#candidate_text1 = \"It is a guide to action that ensures that the military will forever heed Party commands. It is the guiding principle which guarantees the military forces always being under the command of the Party. It is the practical guide for the army always to heed the directions of the  party. He was interested in world history because he read the book.\"\n",
        "\n",
        "calculate_meteor(reference_output, generated_output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3868-FLErMpR"
      },
      "source": [
        "### Dist-N (N-Gram Repetition Rates & N-Gram Diversity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mamcC_NCrMpS",
        "outputId": "55abbaa2-8b83-497b-a006-d608418c9edd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7026769867219591\n"
          ]
        }
      ],
      "source": [
        "# N-Gram Repetition Rates - aka Dist-N\n",
        "'''\n",
        "A low diversity score suggests the model suffers from repetition, and a high diversity score means the\n",
        "model generated text is lexically diverse. - https://arxiv.org/pdf/2210.15097.pdf Lisa Li, page 3\n",
        "'''\n",
        "\n",
        "# code from https://github.com/neural-dialogue-metrics/Distinct-N/tree/main\n",
        "\n",
        "#helper methods\n",
        "from itertools import chain\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "def pad_sequence(sequence, n, pad_left=False, pad_right=False,\n",
        "                 left_pad_symbol=None, right_pad_symbol=None):\n",
        "    sequence = iter(sequence)\n",
        "    if pad_left:\n",
        "        sequence = chain((left_pad_symbol,) * (n - 1), sequence)\n",
        "    if pad_right:\n",
        "        sequence = chain(sequence, (right_pad_symbol,) * (n - 1))\n",
        "    return sequence\n",
        "\n",
        "\n",
        "def ngrams(sequence, n, pad_left=False, pad_right=False,\n",
        "           left_pad_symbol=None, right_pad_symbol=None):\n",
        "    sequence = pad_sequence(sequence, n, pad_left, pad_right,\n",
        "                            left_pad_symbol, right_pad_symbol)\n",
        "\n",
        "    history = []\n",
        "    while n > 1:\n",
        "        history.append(next(sequence))\n",
        "        n -= 1\n",
        "    for item in sequence:\n",
        "        history.append(item)\n",
        "        yield tuple(history)\n",
        "        del history[0]\n",
        "\n",
        "# the real deal\n",
        "def distinct_n_sentence_level(sentence, n):\n",
        "    if len(sentence) == 0:\n",
        "        return 0.0  # Prevent a zero division\n",
        "    distinct_ngrams = set(ngrams(sentence, n))\n",
        "    return len(distinct_ngrams) / len(sentence)\n",
        "\n",
        "\n",
        "def distinct_n_corpus_level(sentences, n):\n",
        "    return sum(distinct_n_sentence_level(sentence, n) for sentence in sentences) / len(sentences)\n",
        "\n",
        "#def calculate_distinctn(candidate_text, ngram_num):\n",
        "#  return distinct_n_corpus_level(candidate_text, ngram_num)\n",
        "\n",
        "#candidate_text = \"It is a guide to action that ensures that the military will forever heed Party commands. It is the guiding principle which guarantees the military forces always being under the command of the Party. It is the practical guide for the army always to heed the directions of the  party. He was interested in world history because he read the book.\"\n",
        "#candidate_text = \"Machine learning is a fascinating field that encompasses a wide range of techniques and algorithms. It involves the use of statistical models and computer systems to perform tasks without explicit programming. Natural language processing, image recognition, and recommendation systems are just a few applications of machine learning. The algorithms learn from data and make predictions or decisions based on that learning. N-gram metrics can be applied to analyze the structure and patterns within this diverse field, providing insights into the relationships between words and phrases. The integration of n-gram analysis enhances our understanding of the language used in machine learning literature and contributes to refining the algorithms for even more accurate predictions.\"\n",
        "candidate_text = clean_tokens(generated_output)\n",
        "\n",
        "ngram_num = 2\n",
        "\n",
        "print(distinct_n_corpus_level(candidate_text, ngram_num))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6DQSMWmrMpT",
        "outputId": "d46ac758-874d-4835-e085-d12852c76e89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N-Gram Diversity (N=2): [14, 15, 15, 13, 23, 26]\n"
          ]
        }
      ],
      "source": [
        "# N-Gram Diversity\n",
        "# DIV = Sum of Dist-N\n",
        "\n",
        "from nltk import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "def calculate_ngram_diversity(text, n):\n",
        "    text = clean_tokens(text)\n",
        "    # Tokenize the text into words\n",
        "    words = [word_tokenize(t) for t in text]\n",
        "\n",
        "    diversity = []\n",
        "    for t in text:\n",
        "      words = word_tokenize(t)\n",
        "      # Generate N-grams\n",
        "      ngrams_list = list(ngrams(words, n))\n",
        "      # Calculate diversity by counting distinct N-grams\n",
        "      diversity.append(len(set(ngrams_list)))\n",
        "\n",
        "    return diversity\n",
        "\n",
        "# Set N for N-grams (e.g., N=2 for bigrams)\n",
        "n_value = 2\n",
        "#candidate_text = \"Machine learning is a fascinating field that encompasses a wide range of techniques and algorithms. It involves the use of statistical models and computer systems to perform tasks without explicit programming. Natural language processing, image recognition, and recommendation systems are just a few applications of machine learning. The algorithms learn from data and make predictions or decisions based on that learning. N-gram metrics can be applied to analyze the structure and patterns within this diverse field, providing insights into the relationships between words and phrases. The integration of n-gram analysis enhances our understanding of the language used in machine learning literature and contributes to refining the algorithms for even more accurate predictions.\"\n",
        "#candidate_text = clean_tokens(sent_tokenize(candidate_text))\n",
        "\n",
        "# Calculate N-Gram Diversity\n",
        "diversity = calculate_ngram_diversity(generated_output, n_value)\n",
        "\n",
        "print(f\"N-Gram Diversity (N={n_value}): {diversity}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ltq8zj03MxB"
      },
      "source": [
        "### Shannon entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68epWdhv3MxC"
      },
      "source": [
        "https://arxiv.org/pdf/2004.10450.pdf - the paper Johann referenced\n",
        "\n",
        "--> In the proposed framework, we evaluate the quality of a single sentence x ∈ X by asking humans for a quality\n",
        "judgment HJ(x). We can define the quality Q of a model as the expected human “quality” judgment for sentences\n",
        "drawn from it: Q(p) = Ex∼p[HJ(x)]\n",
        "\n",
        "-> so we need people to score the quality of the sentences and then use this to measure the quality\n",
        "\n",
        "https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf - original paper by shannon\n",
        "\n",
        "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html - package used here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVWO048-3MxC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import entropy\n",
        "\n",
        "def calculate_shannon(base, HJ): # we need a base and an array of human judgement scores\n",
        "  base = base  # work in units of bits, typically 2\n",
        "  H = entropy(HJ, base=base)\n",
        "\n",
        "  metrics[\"shannon\"] = H\n",
        "  print(f\"Shannon Entropy: {H}\")\n",
        "\n",
        "  return H"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8hKKVs1BjVj"
      },
      "source": [
        "# GPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "SucjrpLICLSe",
        "outputId": "b872e746-e053-4936-b4ee-2ca6e21dc8db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-2f0dca7051eb>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mreference_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mcandidate_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mself_bleu_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreference_set\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcandidate_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mavg_self_bleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_bleu_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py\u001b[0m in \u001b[0;36mcorpus_bleu\u001b[0;34m(list_of_references, hypotheses, weights, smoothing_function, auto_reweigh)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mhyp_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     assert len(list_of_references) == len(hypotheses), (\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0;34m\"The number of hypotheses and their reference(s) should be the \"\u001b[0m \u001b[0;34m\"same \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     )\n",
            "\u001b[0;31mAssertionError\u001b[0m: The number of hypotheses and their reference(s) should be the same "
          ]
        }
      ],
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from rouge import Rouge\n",
        "from nltk import ngrams\n",
        "from nltk.util import ngrams as nltk_ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Sample reference and candidate texts\n",
        "reference_text = \"This is a reference sentence. It serves as an example for testing similarity metrics.\"\n",
        "candidate_text = \"This is an example sentence used for testing the similarity metrics.\"\n",
        "\n",
        "# Metrics dictionary to store scores\n",
        "metrics_dict = {}\n",
        "\n",
        "# 1. BLEU Score\n",
        "bleu_score = sentence_bleu([word_tokenize(reference_text)], word_tokenize(candidate_text))\n",
        "metrics_dict[\"BLEU\"] = bleu_score\n",
        "\n",
        "# 2. SELF-BLEU Score\n",
        "self_bleu_scores = []\n",
        "#for _ in range(10):  # You can adjust the number of iterations\n",
        "for i in candidate_tokens:\n",
        "    reference_set = [word_tokenize(reference_text)]\n",
        "    candidate_set = word_tokenize(candidate_text)\n",
        "#    self_bleu_scores.append(corpus_bleu([reference_set] * len(candidate_set), [candidate_set]))\n",
        "    self_bleu_scores.append(corpus_bleu([reference_set], [candidate_set]))\n",
        "\n",
        "avg_self_bleu = np.mean(self_bleu_scores)\n",
        "metrics_dict[\"SELF-BLEU\"] = avg_self_bleu\n",
        "\n",
        "# 3. ROUGE Score\n",
        "#scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "#rouge_scores = scorer.score(reference_text, candidate_text)\n",
        "rouge = Rouge()\n",
        "rouge_score = rouge.get_scores([word_tokenize(candidate_text)], word_tokenize(reference_text))\n",
        "metrics_dict[\"ROUGE\"] = rouge_score\n",
        "\n",
        "# 4. METEOR Score\n",
        "meteor = meteor_score([reference_text], candidate_text)\n",
        "metrics_dict[\"METEOR\"] = meteor\n",
        "\n",
        "# 5. MAUVE Score\n",
        "# Assuming you have a function `mauve_metric` from a previous example\n",
        "# Please replace the function with your actual implementation\n",
        "mauve_score = mauve_metric(candidate_text, reference_text)\n",
        "metrics_dict[\"MAUVE\"] = mauve_score\n",
        "\n",
        "# 6. N-gram Repetition Rates\n",
        "def ngram_repetition_rate(text, n):\n",
        "    words = word_tokenize(text)\n",
        "    ngrams_list = list(ngrams(words, n))\n",
        "    ngram_counter = Counter(ngrams_list)\n",
        "    repetition_rate = sum(count > 1 for count in ngram_counter.values()) / len(ngrams_list)\n",
        "    return repetition_rate\n",
        "\n",
        "ngram_repetition_rate_2 = ngram_repetition_rate(candidate_text, 2)\n",
        "metrics_dict[\"N-gram Repetition Rate (N=2)\"] = ngram_repetition_rate_2\n",
        "\n",
        "# 7. Repetitiveness (Cosine Similarity of TF-IDF Vectors)\n",
        "def repetitiveness(reference, candidate):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform([reference, candidate])\n",
        "    similarity_matrix = cosine_similarity(tfidf_matrix)\n",
        "    return similarity_matrix[0, 1]\n",
        "\n",
        "repetitiveness_score = repetitiveness(reference_text, candidate_text)\n",
        "metrics_dict[\"Repetitiveness\"] = repetitiveness_score\n",
        "\n",
        "# Print the metrics dictionary\n",
        "print(\"Metrics Dictionary:\")\n",
        "for metric, score in metrics_dict.items():\n",
        "    print(f\"{metric}: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KvhzcY6Bv0L"
      },
      "source": [
        "# Old Tries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGVsqeDZ7W0X"
      },
      "source": [
        "## BLEU and SELF-BLEU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3dcvXjx4HTg",
        "outputId": "e3d8192c-c3ce-489d-bddf-8a1f363ebb25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "#%pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxzOVPgH3Nrq",
        "outputId": "e1253bb5-1399-4e53-89e2-af1943dd7bdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU Score: 2.827255547394629e-155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "# Calculate BLEU score or other evaluation metrics, NEED to use NLP library for BLEU calculation)\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def calculate_bleu():\n",
        "  # Calculate BLEU score\n",
        "  bleu_score = sentence_bleu([reference_tokens], candidate_tokens)\n",
        "  metrics[\"bleu\"] = bleu_score\n",
        "\n",
        "  print(f\"BLEU Score: {bleu_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2ydoLunaUwr"
      },
      "outputs": [],
      "source": [
        "# SELF-BLEU - needs to be fitted to our code\n",
        "\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "'''\n",
        "def get_bleu_score(sentence, remaining_sentences):\n",
        "    lst = []\n",
        "    for i in remaining_sentences:\n",
        "        bleu = sentence_bleu(sentence, i)\n",
        "        lst.append(bleu)\n",
        "    return lst\n",
        "'''\n",
        "\n",
        "def calculate_selfBleu(candidate_tokens):\n",
        "    '''\n",
        "    sentences - list of sentences generated by NLG system -> in our case candidate_tokens\n",
        "    '''\n",
        "    bleu_scores = []\n",
        "\n",
        "    for i in candidate_tokens:\n",
        "        sentences_copy = copy.deepcopy(candidate_tokens)\n",
        "        remaining_sentences = sentences_copy.remove(i)\n",
        "#        print(sentences_copy)\n",
        "#        bleu = get_bleu_score(i,sentences_copy)\n",
        "        bleu = calculate_bleu(i,sentences_copy)\n",
        "        bleu_scores.append(bleu)\n",
        "\n",
        "    self_bleu = np.mean(bleu_scores)\n",
        "\n",
        "    metrics[\"self_bleu\"] = self_bleu\n",
        "    print(f\"SELF_BLEU Score: {self_bleu}\")\n",
        "\n",
        "    return self_bleu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_b4AqsED7eAl"
      },
      "source": [
        "## ROUGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d0tTzr4R9Vq"
      },
      "outputs": [],
      "source": [
        "pip install rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQo-lK4tBbvE"
      },
      "outputs": [],
      "source": [
        "from rouge import Rouge\n",
        "rouge = Rouge()\n",
        "\n",
        "#def calculate_rouge(candidate, reference):\n",
        "def calculate_rouge():\n",
        "    '''\n",
        "    candidate, reference: generated and ground-truth sentences\n",
        "    '''\n",
        "    # Tokenize your reference and generated texts into lists of words or tokens\n",
        "    rouge_score = rouge.get_scores([candidate_tokens], reference_tokens)\n",
        "    metrics[\"rouge\"] = rouge_score\n",
        "    print(f\"ROUGE Score: {rouge_score}\")\n",
        "\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwLteLYl7ggB"
      },
      "source": [
        "## METEOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13MLIy-MaSoI"
      },
      "outputs": [],
      "source": [
        "#METEOR SCORE\n",
        "from nltk.translate import meteor\n",
        "\n",
        "#def calculate_meteor(candidate, reference):\n",
        "def calculate_meteor():\n",
        "  '''\n",
        "  candidate, reference: tokenized list of words in the sentence\n",
        "  '''\n",
        "#  reference_tokens = word_tokenize(reference)\n",
        "#  candidate_tokens = word_tokenize(candidate)\n",
        "  meteor_score = round(meteor([candidate_tokens],reference_tokens), 4)\n",
        "  metrics[\"meteor\"] = meteor_score\n",
        "  print(f\"METEOR Score: {meteor_score}\")\n",
        "\n",
        "  return meteor_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YBVSaCn7jSb"
      },
      "source": [
        "## Word Movers Distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVXi-c9J8TIp"
      },
      "outputs": [],
      "source": [
        "%pip install ot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "38eXMSEmdrIO",
        "outputId": "2926475a-241b-413e-fdb6-cbf4704d30a2"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-ee0b91202bde>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Calculate Word Mover's Distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mwmdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_wmdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2vec_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Word Mover's Distance: {wmdistance}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-ee0b91202bde>\u001b[0m in \u001b[0;36mcalculate_wmdistance\u001b[0;34m(doc1, doc2, model, stop_words)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Calculate Word Mover's Distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwmdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc1_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc2_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mwmdistance\u001b[0;34m(self, document1, document2, norm)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \"\"\"\n\u001b[1;32m    954\u001b[0m         \u001b[0;31m# If POT is attempted to be used, but isn't installed, ImportError will be raised in wmdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0memd2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0;31m# Remove out-of-vocabulary words.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ot'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from nltk.corpus import stopwords\n",
        "#import nltk\n",
        "#nltk.download('stopwords')\n",
        "import gensim.downloader as api\n",
        "\n",
        "# Load pre-trained Word2Vec model (example using 'word2vec-google-news-300')\n",
        "word2vec_model = api.load(\"word2vec-google-news-300\")\n",
        "\n",
        "# Function to calculate Word Mover's Distance\n",
        "def calculate_wmdistance(doc1, doc2, model, stop_words):\n",
        "    # Tokenize and remove stopwords\n",
        "    doc1_tokens = [word for word in doc1.lower().split() if word not in stop_words]\n",
        "    doc2_tokens = [word for word in doc2.lower().split() if word not in stop_words]\n",
        "\n",
        "    # Calculate Word Mover's Distance\n",
        "    distance = model.wmdistance(doc1_tokens, doc2_tokens)\n",
        "\n",
        "    return distance\n",
        "\n",
        "# Example documents\n",
        "document1 = \"Machine learning is fascinating.\"\n",
        "document2 = \"Natural language processing is an interesting field of study.\"\n",
        "\n",
        "# Download stopwords from NLTK\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Calculate Word Mover's Distance\n",
        "wmdistance = calculate_wmdistance(document1, document2, word2vec_model, stop_words)\n",
        "\n",
        "print(f\"Word Mover's Distance: {wmdistance}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjExY4Kc7nWu"
      },
      "source": [
        "## Metrics open for discussion (aka perplexity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alWN0UDjnKT3"
      },
      "source": [
        "Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0xYR6WNqJpy"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "PERPLEXITY\n",
        "we can compute it on already seen set or on part of training set that is new\n",
        "'''\n",
        "\n",
        "import math\n",
        "\n",
        "def calculate_perplexity(language_model, test_data):\n",
        "    total_log_prob = 0\n",
        "    total_words = 0\n",
        "\n",
        "    for sentence in test_data:\n",
        "        context = []  # Initial context\n",
        "        for word in sentence:\n",
        "            total_words += 1\n",
        "            probability = language_model.get_word_probability(word, context)\n",
        "            total_log_prob += math.log(probability)\n",
        "            context.append(word)  # Update context for the next word\n",
        "\n",
        "    perplexity = math.exp(-total_log_prob / total_words)\n",
        "    return perplexity\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7jzehgTkbIB"
      },
      "outputs": [],
      "source": [
        "#approximate the purpose of a text by calculating its lexicon-based topicality scores\n",
        "# https://github.com/Ejhfast/empath-client\n",
        "pip install empath\n",
        "from empath import Empath\n",
        "lexicon = Empath()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZmq9Byo7w0O"
      },
      "source": [
        "### MAUVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSqQ5Ilprus-"
      },
      "outputs": [],
      "source": [
        "# MAUVE: https://github.com/krishnap25/mauve-experiments || https://github.com/krishnap25/mauve\n",
        "pip install nltk==3.4.5\n",
        "# pip install transformers==4.2.0\n",
        "pip install scikit-learn==0.22.1\n",
        "pip install faiss-gpu==1.7.0\n",
        "pip install tqdm==4.40.0 # or higher for all\n",
        "'''\n",
        "numpy>=1.18.1\n",
        "scikit-learn>=0.22.1\n",
        "faiss-cpu>=1.7.0\n",
        "tqdm>=4.40.0\n",
        "'''\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDtG6hJy71Dn"
      },
      "source": [
        "## Diversity Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPbL1UtP743v"
      },
      "source": [
        "### Dist-N (N-Gram Repetition Rates & N-Gram Diversity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VX6Pq90G-nrf",
        "outputId": "55abbaa2-8b83-497b-a006-d608418c9edd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7026769867219591\n"
          ]
        }
      ],
      "source": [
        "# N-Gram Repetition Rates - aka Dist-N\n",
        "'''\n",
        "A low diversity score suggests the model suffers from repetition, and a high diversity score means the\n",
        "model generated text is lexically diverse. - https://arxiv.org/pdf/2210.15097.pdf Lisa Li, page 3\n",
        "'''\n",
        "\n",
        "# code from https://github.com/neural-dialogue-metrics/Distinct-N/tree/main\n",
        "\n",
        "#helper methods\n",
        "from itertools import chain\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "def pad_sequence(sequence, n, pad_left=False, pad_right=False,\n",
        "                 left_pad_symbol=None, right_pad_symbol=None):\n",
        "    sequence = iter(sequence)\n",
        "    if pad_left:\n",
        "        sequence = chain((left_pad_symbol,) * (n - 1), sequence)\n",
        "    if pad_right:\n",
        "        sequence = chain(sequence, (right_pad_symbol,) * (n - 1))\n",
        "    return sequence\n",
        "\n",
        "\n",
        "def ngrams(sequence, n, pad_left=False, pad_right=False,\n",
        "           left_pad_symbol=None, right_pad_symbol=None):\n",
        "    sequence = pad_sequence(sequence, n, pad_left, pad_right,\n",
        "                            left_pad_symbol, right_pad_symbol)\n",
        "\n",
        "    history = []\n",
        "    while n > 1:\n",
        "        history.append(next(sequence))\n",
        "        n -= 1\n",
        "    for item in sequence:\n",
        "        history.append(item)\n",
        "        yield tuple(history)\n",
        "        del history[0]\n",
        "\n",
        "# the real deal\n",
        "def distinct_n_sentence_level(sentence, n):\n",
        "    if len(sentence) == 0:\n",
        "        return 0.0  # Prevent a zero division\n",
        "    distinct_ngrams = set(ngrams(sentence, n))\n",
        "    return len(distinct_ngrams) / len(sentence)\n",
        "\n",
        "\n",
        "def distinct_n_corpus_level(sentences, n):\n",
        "    return sum(distinct_n_sentence_level(sentence, n) for sentence in sentences) / len(sentences)\n",
        "\n",
        "#def calculate_distinctn(candidate_text, ngram_num):\n",
        "#  return distinct_n_corpus_level(candidate_text, ngram_num)\n",
        "\n",
        "#reference_text = \"It is a guide to action which ensures that the military always obeys the commands of the party. He read the book because he was interested in world history.\"\n",
        "#candidate_text = \"It is a guide to action that ensures that the military will forever heed Party commands. It is the guiding principle which guarantees the military forces always being under the command of the Party. It is the practical guide for the army always to heed the directions of the  party. He was interested in world history because he read the book.\"\n",
        "candidate_text = \"Machine learning is a fascinating field that encompasses a wide range of techniques and algorithms. It involves the use of statistical models and computer systems to perform tasks without explicit programming. Natural language processing, image recognition, and recommendation systems are just a few applications of machine learning. The algorithms learn from data and make predictions or decisions based on that learning. N-gram metrics can be applied to analyze the structure and patterns within this diverse field, providing insights into the relationships between words and phrases. The integration of n-gram analysis enhances our understanding of the language used in machine learning literature and contributes to refining the algorithms for even more accurate predictions.\"\n",
        "#reference_text = clean_tokens(sent_tokenize(reference_text))\n",
        "candidate_text = clean_tokens(sent_tokenize(candidate_text))\n",
        "\n",
        "ngram_num = 2\n",
        "\n",
        "print(distinct_n_corpus_level(candidate_text, ngram_num))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q7VB9oV-8rz",
        "outputId": "d46ac758-874d-4835-e085-d12852c76e89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N-Gram Diversity (N=2): [14, 15, 15, 13, 23, 26]\n"
          ]
        }
      ],
      "source": [
        "# N-Gram Diversity\n",
        "# DIV = Sum of Dist-N\n",
        "\n",
        "from nltk import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "def calculate_ngram_diversity(text, n):\n",
        "    # Tokenize the text into words\n",
        "    words = [word_tokenize(t) for t in text]\n",
        "\n",
        "    diversity = []\n",
        "    for t in text:\n",
        "      words = word_tokenize(t)\n",
        "      # Generate N-grams\n",
        "      ngrams_list = list(ngrams(words, n))\n",
        "      # Calculate diversity by counting distinct N-grams\n",
        "      diversity.append(len(set(ngrams_list)))\n",
        "\n",
        "    return diversity\n",
        "\n",
        "# Set N for N-grams (e.g., N=2 for bigrams)\n",
        "n_value = 2\n",
        "candidate_text = \"Machine learning is a fascinating field that encompasses a wide range of techniques and algorithms. It involves the use of statistical models and computer systems to perform tasks without explicit programming. Natural language processing, image recognition, and recommendation systems are just a few applications of machine learning. The algorithms learn from data and make predictions or decisions based on that learning. N-gram metrics can be applied to analyze the structure and patterns within this diverse field, providing insights into the relationships between words and phrases. The integration of n-gram analysis enhances our understanding of the language used in machine learning literature and contributes to refining the algorithms for even more accurate predictions.\"\n",
        "candidate_text = clean_tokens(sent_tokenize(candidate_text))\n",
        "\n",
        "# Calculate N-Gram Diversity\n",
        "diversity = calculate_ngram_diversity(candidate_text, n_value)\n",
        "\n",
        "print(f\"N-Gram Diversity (N={n_value}): {diversity}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRbgY1Gw8Dkw"
      },
      "source": [
        "### Shannon entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z_E0xEiRjQp"
      },
      "source": [
        "https://arxiv.org/pdf/2004.10450.pdf - the paper Johann referenced\n",
        "\n",
        "--> In the proposed framework, we evaluate the quality of a single sentence x ∈ X by asking humans for a quality\n",
        "judgment HJ(x). We can define the quality Q of a model as the expected human “quality” judgment for sentences\n",
        "drawn from it: Q(p) = Ex∼p[HJ(x)]\n",
        "\n",
        "-> so we need people to score the quality of the sentences and then use this to measure the quality\n",
        "\n",
        "https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf - original paper by shannon\n",
        "\n",
        "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html - package used here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRiZihSD-6f1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import entropy\n",
        "\n",
        "def calculate_shannon(base, HJ): # we need a base and an array of human judgement scores\n",
        "  base = base  # work in units of bits, typically 2\n",
        "  H = entropy(HJ, base=base)\n",
        "\n",
        "  metrics[\"shannon\"] = H\n",
        "  print(f\"Shannon Entropy: {H}\")\n",
        "\n",
        "  return H"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbeq1jiv8GKE"
      },
      "source": [
        "### Syntactic and lexical diversity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMyNM7hJRS_H"
      },
      "source": [
        "Syntactic and lexical diversity - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8049133/pdf/peerj-cs-07-443.pdf page 7\n",
        "\n",
        "NE-recognizer and POS-tagger provided in the Python spaCy (https://spacy.io/) package to find the NE- and POS-tags as well as the neuralcoref (https://github.com/huggingface/neuralcoref) extension to detect coreference clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuXvOilnQRFK"
      },
      "outputs": [],
      "source": [
        "pip install $(spacy info en_core_web_sm --url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MReftUbaQSFC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6nxrzVh8OX5"
      },
      "source": [
        "### Repetitiveness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NypYcA117sFf"
      },
      "source": [
        "From Fröhling: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8049133/pdf/peerj-cs-07-443.pdf\n",
        "\n",
        "We try to expose those statistical differences, assumed to be easiest to be picked up by automated detection methods, through the share of stop-words, unique words and words from “top-lists” in a text’s total words. We expect a more diverse, human-written text\n",
        "to have a higher share of unique words and a lower share of top-words and words from “top-lists”. We propose to expose the repetitiveness by calculating the n-gram overlap of words (lexical repetition) and POS-tags (syntactic repetition) in consecutive sentences. Human text is expected to be less repetitive both in sentence structure and word choice. We introduce the “conjunction overlap” as a measure of the n-gram overlap around and-conjunctions to make explicit the reported failure of language models of plainly\n",
        "repeating words around those conjunctions.\n",
        "\n",
        "Take the stop-words defined by the spaCy package and take a list with the top 10,000 words (https://github.com/first20hours/google-10000-english) used in English determined by Google to calculate the share of a text’s words that are in the top 100, top 1,000 and top 10,000 words of that list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtfONNSH_oOG"
      },
      "outputs": [],
      "source": [
        "# As this paper does not give a concrete implementation, we try to recreate it based on the information stated the cell above\n",
        "\n",
        "import spacy\n",
        "import requests\n",
        "from collections import Counter\n",
        "from nltk import ngrams\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download the list of top 10,000 English words\n",
        "url = \"https://raw.githubusercontent.com/first20hours/google-10000-english/master/google-10000-english.txt\"\n",
        "response = requests.get(url)\n",
        "top_words = set(response.text.split())\n",
        "\n",
        "# Load spaCy English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def get_word_stats(text):\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Extract words and stopwords\n",
        "    words = [token.text.lower() for token in doc if token.is_alpha]\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    filtered_words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # Calculate share of words in the top lists\n",
        "    top_100_words = [word for word in filtered_words if word in top_words]\n",
        "    top_1000_words = top_100_words[:1000]\n",
        "    top_10000_words = top_100_words[:10000]\n",
        "\n",
        "    share_top_100 = len(top_100_words) / len(filtered_words)\n",
        "    share_top_1000 = len(top_1000_words) / len(filtered_words)\n",
        "    share_top_10000 = len(top_10000_words) / len(filtered_words)\n",
        "\n",
        "    return share_top_100, share_top_1000, share_top_10000\n",
        "\n",
        "def get_ngram_overlap(text, n):\n",
        "    sentences = [sent.text for sent in nlp(text).sents]\n",
        "    ngrams_list = [ngrams(sent.split(), n) for sent in sentences]\n",
        "    ngram_counts = Counter(ngram for sublist in ngrams_list for ngram in sublist)\n",
        "\n",
        "    return ngram_counts\n",
        "\n",
        "# Example text\n",
        "text = \"We try to expose those statistical differences, assumed to be easiest to be picked up by automated detection methods, through the share of stop-words, unique words and words from 'top-lists' in a text’s total words.\"\n",
        "\n",
        "# Calculate word stats\n",
        "share_top_100, share_top_1000, share_top_10000 = get_word_stats(text)\n",
        "print(f\"Share of words in top 100: {share_top_100:.2%}\")\n",
        "print(f\"Share of words in top 1000: {share_top_1000:.2%}\")\n",
        "print(f\"Share of words in top 10000: {share_top_10000:.2%}\")\n",
        "\n",
        "# Calculate n-gram overlap\n",
        "ngram_counts = get_ngram_overlap(text, 2)\n",
        "print(\"N-gram Counts:\")\n",
        "for ngram, count in ngram_counts.items():\n",
        "    print(f\"{ngram}: {count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztBHbeuH8Pc8"
      },
      "source": [
        "## Coherence Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0PhzGZZ5w-q"
      },
      "outputs": [],
      "source": [
        "# similarity between the prompt and the continuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WsEvvfL57dh"
      },
      "outputs": [],
      "source": [
        "# learn coreference clusters and track the appearance of their entities throughout the text\n",
        "# how? -> count transitions between subject, object, other, non present (NIL?) entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXvrDSSf6K8Z"
      },
      "outputs": [],
      "source": [
        "# Number of categories and amount of focus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvWircYs6PRf"
      },
      "outputs": [],
      "source": [
        "# Yule's statistic Q for measuring semantic associaton between word-pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        },
        "id": "7gEiQf-iz5Ry",
        "outputId": "43a46a53-adf8-4855-ca6f-a1432bce6a55"
      },
      "outputs": [
        {
          "ename": "LookupError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-54bd13bc58e0>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Calculate Yule's Q for the example text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myules_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Print the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-54bd13bc58e0>\u001b[0m in \u001b[0;36myules_q\u001b[0;34m(text, n)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0myules_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Tokenize the text and remove stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Generate n-grams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     return [\n\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "from nltk import FreqDist\n",
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def yules_q(text, n):\n",
        "    # Tokenize the text and remove stopwords\n",
        "    words = [word.lower() for word in word_tokenize(text) if word.isalpha() and word.lower() not in stopwords.words('english')]\n",
        "\n",
        "    # Generate n-grams\n",
        "    ngrams_list = list(ngrams(words, n))\n",
        "\n",
        "    # Calculate observed and expected frequencies\n",
        "    freq_dist = FreqDist(ngrams_list)\n",
        "    observed_freq = sum(freq_dist.values())\n",
        "\n",
        "    m1 = FreqDist(words)\n",
        "    expected_freq = sum([(freq * (freq - 1)) for freq in m1.values()])\n",
        "\n",
        "    # Calculate Yule's Q\n",
        "    if expected_freq == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        yules_q = (observed_freq - expected_freq) / (observed_freq + expected_freq)\n",
        "        return yules_q\n",
        "\n",
        "# Example text\n",
        "example_text = \"This is an example sentence. Another example sentence for testing.\"\n",
        "\n",
        "# Set the value of N for N-grams (e.g., N=2 for bigrams)\n",
        "n_value = 2\n",
        "\n",
        "# Calculate Yule's Q for the example text\n",
        "result = yules_q(example_text, n_value)\n",
        "\n",
        "# Print the result\n",
        "print(f\"Yule's Q (N={n_value}): {result}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0311ba6ddd6747b493b665088e264e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfb031f85b8741238ab093604ce67c1d",
            "placeholder": "​",
            "style": "IPY_MODEL_a0ae12a671f348f18781c59c4e9a19a0",
            "value": " 242M/242M [00:01&lt;00:00, 193MB/s]"
          }
        },
        "0be19a9004074149a2c452fb8eeddee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_339457b78c18460ab677088984211f78",
            "placeholder": "​",
            "style": "IPY_MODEL_6e58beda6116409fbc49a8c9954a9904",
            "value": "generation_config.json: 100%"
          }
        },
        "0c8f3ee5ad4e4685ac6db72ab72996cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a28eaf02920746c48b129fa9365589d5",
            "max": 1206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba5cc303d8d54defaca056607bbca637",
            "value": 1206
          }
        },
        "1a5f209070e84ed0857d0e6f9ca416bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d75cb6e254a4831a32e8cec85599cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d2f0364d6784ca3a9c9271481966e78",
              "IPY_MODEL_6338806ce15448a28135496edd3f7c18",
              "IPY_MODEL_f855834c6fd346779bb56714d9b71a37"
            ],
            "layout": "IPY_MODEL_e4b3446c11a24d73bf1f8d54bfa26f96"
          }
        },
        "1ed67a1e9fcd4f8fa0c604de6adb73d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fe415dec4a943aa9256ec52fbec5b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24573e0a215f40d39656221f00068cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccce8832960849e6979223532e40f60d",
            "placeholder": "​",
            "style": "IPY_MODEL_efa08318e8fc42b2b367c09475413a23",
            "value": "tokenizer.json: 100%"
          }
        },
        "321b1a69883542a6a0e0217787b31490": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "339457b78c18460ab677088984211f78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3952f767ae9343009ed820a2baf7a207": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3caa5b588aae4b0c801008c8fcc0a0d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd9c0b17f06f44f6ab2a4c6c3a4263c7",
              "IPY_MODEL_0c8f3ee5ad4e4685ac6db72ab72996cb",
              "IPY_MODEL_71af837a097a41bbad0af33f23db8891"
            ],
            "layout": "IPY_MODEL_1a5f209070e84ed0857d0e6f9ca416bb"
          }
        },
        "3e199622a303426d8774e64ff4e9f65a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fa26c51bc4d4e2e8abc0aa0d700e6f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54c3b399b9584a09a7a8c490547201cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54f4fa1afd0b4487b616108e1c73e372": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0be19a9004074149a2c452fb8eeddee5",
              "IPY_MODEL_c977fe7d9fe547d792e1d9240831b906",
              "IPY_MODEL_a547240588ea48f39719115d8ba91b3c"
            ],
            "layout": "IPY_MODEL_952dca5debd04f6096ea1cf2aca88065"
          }
        },
        "55e3c756adde40c18fbcf3acde5423f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b524834f8b414485850c1dee1dd014cd",
              "IPY_MODEL_d15b51d3188a454897ef4856a7cdecbd",
              "IPY_MODEL_d2850950d5754cd784e53cf9c80249e8"
            ],
            "layout": "IPY_MODEL_7168e79d74c245389d93daa05d7878fe"
          }
        },
        "5c5fa62661ff40c095c285bd56d2f2eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "609e4cac76c949a9aee582c7b229a016": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6309e5e0c1134b99bf86af05ab5e0fcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5f01a6dbf584731b2fd87d39e65b8e7",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1d77f25410c43fdb93c8b513d8078b0",
            "value": 1389353
          }
        },
        "6338806ce15448a28135496edd3f7c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a434e7ca027b49cab49c8b970db7909c",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_321b1a69883542a6a0e0217787b31490",
            "value": 791656
          }
        },
        "6e58beda6116409fbc49a8c9954a9904": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7168e79d74c245389d93daa05d7878fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71af837a097a41bbad0af33f23db8891": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0edb19549154bda9184dd0998bdcc57",
            "placeholder": "​",
            "style": "IPY_MODEL_f5386ef74d5c4081b877236e302c12e9",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 85.3kB/s]"
          }
        },
        "74489e9e19934688b7b81d7a0c281135": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "776ec07692e146638b9b40aad6cc8814": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f03a447c14c4903a66b135352b37060": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "844c95e38018458780d323cacdcfc7e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84ad48ee7c35447fb0ac8b5c7227cfa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b144412725a49f5aba0976617f26cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_776ec07692e146638b9b40aad6cc8814",
            "placeholder": "​",
            "style": "IPY_MODEL_d8b184cd953f418897ec8ceba1456e04",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 46.4MB/s]"
          }
        },
        "8d2f0364d6784ca3a9c9271481966e78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd8323f478c04388879078e0969bc079",
            "placeholder": "​",
            "style": "IPY_MODEL_1ed67a1e9fcd4f8fa0c604de6adb73d5",
            "value": "spiece.model: 100%"
          }
        },
        "952dca5debd04f6096ea1cf2aca88065": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0ae12a671f348f18781c59c4e9a19a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a28eaf02920746c48b129fa9365589d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a434e7ca027b49cab49c8b970db7909c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a49df3da0b14435f8d9c5785544af28b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a547240588ea48f39719115d8ba91b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb528c2717f048b981db4cd79b401234",
            "placeholder": "​",
            "style": "IPY_MODEL_e4131f9460e74e59a24e999ac5e51ca6",
            "value": " 147/147 [00:00&lt;00:00, 10.3kB/s]"
          }
        },
        "a8a52ed379d14e149db9405669c66a1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b27571c22c584b8aa14b29df5e3209e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3199bf3ce634e0eb79addef54c803d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de55b0ced39f42b4ba8107994b5d4c2c",
              "IPY_MODEL_c8c7ee5d989b4e5d93f44cae536e77e4",
              "IPY_MODEL_0311ba6ddd6747b493b665088e264e3e"
            ],
            "layout": "IPY_MODEL_defffcd0ea3447d48ec47ad2c9302670"
          }
        },
        "b524834f8b414485850c1dee1dd014cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b66dc19fd9b5466fa24c8f874ec2864c",
            "placeholder": "​",
            "style": "IPY_MODEL_84ad48ee7c35447fb0ac8b5c7227cfa6",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b66dc19fd9b5466fa24c8f874ec2864c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b942864395754c9684ff7ef7f3aa0e73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba5cc303d8d54defaca056607bbca637": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb528c2717f048b981db4cd79b401234": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd9c0b17f06f44f6ab2a4c6c3a4263c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_609e4cac76c949a9aee582c7b229a016",
            "placeholder": "​",
            "style": "IPY_MODEL_1fe415dec4a943aa9256ec52fbec5b1a",
            "value": "config.json: 100%"
          }
        },
        "c0edb19549154bda9184dd0998bdcc57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c67b4dfcca7b4e048333077f3d61d577": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24573e0a215f40d39656221f00068cbf",
              "IPY_MODEL_6309e5e0c1134b99bf86af05ab5e0fcd",
              "IPY_MODEL_8b144412725a49f5aba0976617f26cdc"
            ],
            "layout": "IPY_MODEL_b942864395754c9684ff7ef7f3aa0e73"
          }
        },
        "c8c7ee5d989b4e5d93f44cae536e77e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54c3b399b9584a09a7a8c490547201cf",
            "max": 242043056,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e199622a303426d8774e64ff4e9f65a",
            "value": 242043056
          }
        },
        "c977fe7d9fe547d792e1d9240831b906": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fffa10027ea04373b66ceac49223420e",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b27571c22c584b8aa14b29df5e3209e1",
            "value": 147
          }
        },
        "ccce8832960849e6979223532e40f60d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfb031f85b8741238ab093604ce67c1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d15b51d3188a454897ef4856a7cdecbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8a52ed379d14e149db9405669c66a1a",
            "max": 2324,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3952f767ae9343009ed820a2baf7a207",
            "value": 2324
          }
        },
        "d2850950d5754cd784e53cf9c80249e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a49df3da0b14435f8d9c5785544af28b",
            "placeholder": "​",
            "style": "IPY_MODEL_3fa26c51bc4d4e2e8abc0aa0d700e6f4",
            "value": " 2.32k/2.32k [00:00&lt;00:00, 79.0kB/s]"
          }
        },
        "d5f01a6dbf584731b2fd87d39e65b8e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8b184cd953f418897ec8ceba1456e04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de55b0ced39f42b4ba8107994b5d4c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74489e9e19934688b7b81d7a0c281135",
            "placeholder": "​",
            "style": "IPY_MODEL_844c95e38018458780d323cacdcfc7e7",
            "value": "model.safetensors: 100%"
          }
        },
        "defffcd0ea3447d48ec47ad2c9302670": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1d77f25410c43fdb93c8b513d8078b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4131f9460e74e59a24e999ac5e51ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4b3446c11a24d73bf1f8d54bfa26f96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efa08318e8fc42b2b367c09475413a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5386ef74d5c4081b877236e302c12e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f855834c6fd346779bb56714d9b71a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f03a447c14c4903a66b135352b37060",
            "placeholder": "​",
            "style": "IPY_MODEL_5c5fa62661ff40c095c285bd56d2f2eb",
            "value": " 792k/792k [00:00&lt;00:00, 10.3MB/s]"
          }
        },
        "fd8323f478c04388879078e0969bc079": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fffa10027ea04373b66ceac49223420e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
